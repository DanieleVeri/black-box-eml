{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nNNmQ5x5YJaS",
        "JcyNrxy43Bgb",
        "S2USqSnCBVDM",
        "C00w0zpdczA4",
        "cUbgkjkyrII_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNNmQ5x5YJaS"
      },
      "source": [
        "# ðŸ“¥ Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCrU3TGEYlBp"
      },
      "source": [
        "#@title GPyopt\n",
        "!pip install GPyOpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsM5SqajYG_V"
      },
      "source": [
        "#@title CPLEX\n",
        "\n",
        "!wget https://api.wandb.ai/artifactsV2/gcp-us/veri/QXJ0aWZhY3Q6MjU1ODAzMjI=/69b1b89a73a7d0931fbfdb355eb147c3 -O cplex_studio1210.linux-x86-64.bin\n",
        "!wget https://api.wandb.ai/artifactsV2/gcp-us/veri/QXJ0aWZhY3Q6MjU1ODAzMjI=/97133b747b0114a4e3dba77ab26d68d5 -O response.properties\n",
        "\n",
        "!pip install docplex\n",
        "!sh cplex_studio1210.linux-x86-64.bin -f response.properties\n",
        "!python3 /opt/ibm/ILOG/CPLEX_Studio1210/python/setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPqw-nj0X3v"
      },
      "source": [
        "#@title Tensorflow addons\n",
        "\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "BaPHqIopVAWW"
      },
      "source": [
        "#@title EMLlib\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!git clone https://github.com/DanieleVeri/emllib.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcyNrxy43Bgb"
      },
      "source": [
        "# ðŸ“‘ Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2SDDKf13x94"
      },
      "source": [
        "#@title Base import and seed\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "if not 'emllib' in sys.path: sys.path.insert(1, 'emllib')\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "admZL6drfYtp"
      },
      "source": [
        "##Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "_X0Nzl3PeFAw"
      },
      "source": [
        "#@title Problem class\n",
        "\n",
        "class Problem:\n",
        "\n",
        "    def __init__(self, name, fun, input_type, input_bounds, constraint_cb=None):\n",
        "        self.name = name\n",
        "        self.fun = fun\n",
        "        self.input_type = input_type\n",
        "        self.input_bounds = input_bounds\n",
        "        self.input_shape = len(self.input_bounds)\n",
        "        self.constraint_cb = constraint_cb\n",
        "\n",
        "    def get_dataset(self, n_points):\n",
        "        x = np.random.rand(n_points, self.input_shape)\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            lb = b[0]\n",
        "            ub = b[1]\n",
        "            if self.input_type[i] == \"int\":\n",
        "                x[:,i] = np.random.randint(lb, high=ub, size=n_points)\n",
        "            else:\n",
        "                x[:,i] *= ub - lb\n",
        "                x[:,i] += lb\n",
        "        y = np.zeros((n_points))\n",
        "        for i in range(n_points):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "        return x, y\n",
        "\n",
        "    def get_grid(self, n_points):\n",
        "        x_list = []\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            lb = b[0]\n",
        "            ub = b[1]\n",
        "            if self.input_type[i] == \"int\":\n",
        "                x_list.append(np.arange(lb, ub, max(1, (ub-lb)//n_points)))\n",
        "            else:\n",
        "                x_list.append(np.arange(lb, ub, (ub-lb)/n_points))\n",
        "        x = np.array(np.meshgrid(*x_list)).reshape(self.input_shape,-1).T\n",
        "        y = np.zeros((x.shape[0]))\n",
        "        for i in range(x.shape[0]):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97wo6u7pHxT"
      },
      "source": [
        "##TFP utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Cj1QIgqNpSi3"
      },
      "source": [
        "#@title Build and plot\n",
        "\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "def build_probabilistic_regressor(input_shape, depth=4, width=20):\n",
        "    mdl = tf.keras.Sequential()\n",
        "    mdl.add(tf.keras.layers.Input(shape=(input_shape,), dtype='float32'))\n",
        "    for i in range(depth):\n",
        "        mdl.add(tf.keras.layers.Dense(width, activation='relu'))\n",
        "    mdl.add(tf.keras.layers.Dense(2, activation='linear'))\n",
        "    lf = lambda t: tfp.distributions.Normal(loc=t[:, :1], \n",
        "                                            scale=tf.keras.backend.exp(t[:, 1:]))\n",
        "    mdl.add(tfp.layers.DistributionLambda(lf))\n",
        "    return mdl\n",
        "\n",
        "def dlambda_likelihood(y_true, dist):\n",
        "    return -dist.log_prob(y_true)\n",
        "\n",
        "def plot_prob_predictions(mdl, x, y):\n",
        "    prob_pred = mdl(np.expand_dims(x, axis=1))\n",
        "    pred = prob_pred.mean().numpy().ravel()\n",
        "    std_pred = prob_pred.stddev().numpy().ravel()\n",
        "    plt.plot(x, y, c=\"grey\")\n",
        "    plt.plot(x, pred)\n",
        "    plt.fill_between(x, pred-std_pred, pred+std_pred, \n",
        "                    alpha=0.3, color='tab:blue', label='+/- std')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txjrAWgNO1RE"
      },
      "source": [
        "## Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "j9z-F2az2mtZ"
      },
      "source": [
        "#@title GPy opt - LCB\n",
        "\n",
        "import GPy\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "\n",
        "def bayesian_opt_gpy(problem, iterations, starting_points):\n",
        "    set_seed()\n",
        "\n",
        "    x,y = problem.get_dataset(starting_points)\n",
        "    if problem.input_shape == 1:\n",
        "        x = x.reshape(-1, 1)\n",
        "\n",
        "    bds = []\n",
        "    for i,b in enumerate(problem.input_bounds):\n",
        "        bds.append({\n",
        "            'name': 'X'+str(i), \n",
        "            'type': 'continuous', \n",
        "            'domain': problem.input_bounds[i]})\n",
        "        \n",
        "    def wrapper(in_x):\n",
        "        return problem.fun(in_x.ravel())\n",
        "\n",
        "    kernel = GPy.kern.Matern52(input_dim=1, variance=1.0, lengthscale=1.0)\n",
        "    optimizer = BayesianOptimization(f=wrapper, \n",
        "                                    domain=bds,\n",
        "                                    model_type='GP',\n",
        "                                    kernel=kernel,\n",
        "                                    acquisition_type ='LCB',\n",
        "                                    acquisition_jitter = 0.01,\n",
        "                                    X=x,\n",
        "                                    Y=y.reshape(-1,1),\n",
        "                                    exact_feval=False,\n",
        "                                    normalize_Y=True,\n",
        "                                    maximize=False)\n",
        "\n",
        "    optimizer.run_optimization(max_iter=iterations)\n",
        "    optimizer.plot_acquisition()\n",
        "    print(\"Min found:\", optimizer.x_opt, optimizer.fx_opt)\n",
        "    if ENABLE_WANDB:\n",
        "        wandb.log({\n",
        "            \"min_found\": np.min(optimizer.get_evaluations()[1]),\n",
        "            \"n_iterations\": np.argmin(optimizer.get_evaluations()[1])+1-starting_points\n",
        "        })\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWebt0aFQFWB"
      },
      "source": [
        "## EML utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "eKQuuVzEAFdY"
      },
      "source": [
        "#@title Parse TFP model\n",
        "\n",
        "from eml.net.reader import keras_reader\n",
        "\n",
        "def parse_tfp(model):\n",
        "    in_shape = model.input_shape[1]\n",
        "    mdl_no_dist = tf.keras.Sequential()\n",
        "    mdl_no_dist.add(tf.keras.layers.Input(shape=(in_shape,), dtype='float32'))\n",
        "    for i in range(len(model.layers)-2):\n",
        "        w = model.layers[i].weights[1].shape[0]\n",
        "        mdl_no_dist.add(tf.keras.layers.Dense(w, activation='relu'))\n",
        "    mdl_no_dist.add(tf.keras.layers.Dense(2, activation='linear'))\n",
        "\n",
        "    mdl_no_dist.set_weights(model.get_weights())\n",
        "\n",
        "    nn = keras_reader.read_keras_sequential(mdl_no_dist)\n",
        "    return nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sGBt_pBSDV"
      },
      "source": [
        "#@title Bounds\n",
        "\n",
        "from eml.net.process import ibr_bounds\n",
        "\n",
        "def propagate_bound(parsed_model, bounds):\n",
        "    bounds = np.array(bounds)\n",
        "    parsed_model.layer(0).update_lb(bounds[:,0])\n",
        "    parsed_model.layer(0).update_ub(bounds[:,1])\n",
        "    ibr_bounds(parsed_model)\n",
        "    return parsed_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "YaQm5IIOJKKh"
      },
      "source": [
        "#@title Encode model\n",
        "\n",
        "from eml.backend import cplex_backend\n",
        "import docplex.mp.model as cpx\n",
        "from eml.net import embed\n",
        "\n",
        "def embed_model(bkd, cplex, parsed_model, vtype, bounds):\n",
        "    mean_lb = parsed_model.layer(-1).lb()[0]  # bounds computed with propagate bounds method\n",
        "    mean_ub = parsed_model.layer(-1).ub()[0]\n",
        "    std_lb = parsed_model.layer(-1).lb()[1]\n",
        "    std_ub = parsed_model.layer(-1).ub()[1]\n",
        "\n",
        "    xvars = []\n",
        "    for i,b in enumerate(bounds):\n",
        "        if vtype[i] == \"int\":\n",
        "            xvars.append(cplex.integer_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "        else:\n",
        "            xvars.append(cplex.continuous_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "\n",
        "    yvars = [cplex.continuous_var(lb=mean_lb, ub=mean_ub, name=\"out_mean\"), \n",
        "            cplex.continuous_var(lb=std_lb, ub=std_ub, name=\"out_std\")]\n",
        "\n",
        "    embed.encode(bkd, parsed_model, cplex, xvars, yvars, 'nn')\n",
        "    return xvars, yvars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Oacl6WbaqGkm"
      },
      "source": [
        "#@title PWL helper\n",
        "\n",
        "from eml.util import encode_pwl\n",
        "from scipy.stats import norm\n",
        "\n",
        "def generate_range(lb, ub, nnodes=7):\n",
        "    if (lb >= -3 and ub <= 3) or (lb < -3 and ub <= -3) or (ub > 3 and lb >= 3):\n",
        "        return np.linspace(lb, ub, nnodes)\n",
        "    if lb < -3 and ub <= 3:\n",
        "        return np.concatenate((\n",
        "            np.linspace(lb, -3, min(abs(int(lb+3)), 3), endpoint=False),\n",
        "            np.linspace(-3, ub, nnodes)\n",
        "        ))\n",
        "    if lb >= -3 and ub > 3:\n",
        "        return np.concatenate((\n",
        "            np.linspace(lb, 3, nnodes, endpoint=False),\n",
        "            np.linspace(3, ub, min(abs(int(ub-3)), 3))\n",
        "        ))\n",
        "    if lb < -3 and ub > 3:\n",
        "        return np.concatenate((\n",
        "            np.linspace(lb, -3, min(abs(int(lb+3)), 3), endpoint=False),\n",
        "            np.linspace(-3, 3, nnodes, endpoint=False),\n",
        "            np.linspace(3, ub, min(abs(int(ub-3)), 3))\n",
        "        ))\n",
        "\n",
        "def pwl_exp(bkd, cplex, var, nnodes=7):\n",
        "    xx = generate_range(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(math.exp, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=np.max(yy), name=\"exp_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_normal_cdf(bkd, cplex, var, nnodes=11):\n",
        "    xx = generate_range(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(norm.cdf, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=1, name=\"ncdf_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_normal_pdf(bkd, cplex, var, nnodes=11):\n",
        "    xx = generate_range(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(norm.pdf, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=1, name=\"npdf_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_sample_dist(bkd, cplex, vars, samples, vtype, bounds, nnodes=20):\n",
        "    mapf = lambda x: np.min(np.sum(np.abs(samples - x), axis=1)) / len(bounds)\n",
        "    p = Problem(None, mapf, vtype, bounds)\n",
        "    x,y = p.get_grid(nnodes)\n",
        "    ub = np.diff(np.array(bounds), axis=1)\n",
        "    ub = np.sum(ub)\n",
        "    v = [cplex.continuous_var(lb=0, ub=ub, name=\"dist_out\")]+vars\n",
        "    encode_pwl(bkd, cplex, v, [y,*x.T])\n",
        "    return v[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2oK4x9eI3W"
      },
      "source": [
        "## ðŸ”„ Optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "xC_4qcVo7u5Y"
      },
      "source": [
        "#@title Base Experiment\n",
        "\n",
        "import time\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "class BaseExperiment:\n",
        "    def __init__(self, problem, starting_points, iterations, \n",
        "                 epochs, lr, weight_decay, depth, width, batch_size, \n",
        "                 solver_timeout):\n",
        "        set_seed()\n",
        "        self.problem = problem\n",
        "        self.starting_points = starting_points\n",
        "        self.iterations = iterations\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.depth = depth\n",
        "        self.width = width\n",
        "        self.batch_size = batch_size\n",
        "        self.solver_timeout = solver_timeout\n",
        "        self.x_samples, self.y_samples = problem.get_dataset(starting_points)\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def solution_log(self, solution):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_X(self, x):\n",
        "        bounds = np.array(self.problem.input_bounds)\n",
        "        return (x-bounds[:,0]) / (bounds[:,1]-bounds[:,0])\n",
        "\n",
        "    def normalize_Y(self, y):\n",
        "        min, max = np.min(self.y_samples), np.max(self.y_samples)\n",
        "        return (y-min) / (max-min)\n",
        "\n",
        "    def reverse_normalize_X(self, norm_x, milp_expr=False):\n",
        "        bounds = np.array(self.problem.input_bounds)\n",
        "        if milp_expr:  \n",
        "            # for cplex variables, np array not supported\n",
        "            bounds_range = np.squeeze(np.diff(bounds, axis=1))\n",
        "            xvars = []\n",
        "            for i,x in enumerate(norm_x):\n",
        "                xvars.append(x * bounds_range[i] + bounds[i,0])\n",
        "            return xvars\n",
        "        return (bounds[:,1]-bounds[:,0])*norm_x + bounds[:,0]\n",
        "\n",
        "    def reverse_normalize_Y(self, norm_y, stddev=False):\n",
        "        min, max = np.min(self.y_samples), np.max(self.y_samples)\n",
        "        if stddev:\n",
        "            return norm_y*(max-min)\n",
        "        return (max-min)*norm_y + min\n",
        "\n",
        "    def plot(self, hstory, keras_mdl):\n",
        "        if self.problem.input_shape <= 2:\n",
        "            x,y = self.problem.get_grid(100)\n",
        "            prob_pred = keras_mdl(self.normalize_X(x))\n",
        "            pred = prob_pred.mean().numpy().ravel()\n",
        "            pred = self.reverse_normalize_Y(pred)\n",
        "            std_pred = prob_pred.stddev().numpy().ravel()\n",
        "            std_pred = self.reverse_normalize_Y(std_pred, stddev=True)\n",
        "\n",
        "        plt.plot(hstory.history[\"loss\"])\n",
        "        plt.savefig('train_loss.png')\n",
        "        plt.show()\n",
        "        \n",
        "        fig = plt.figure(figsize=(15,10))\n",
        "        if self.problem.input_shape == 1:   # 1D domain\n",
        "            plt.xlim(self.problem.input_bounds[0])\n",
        "            x = np.squeeze(x)\n",
        "            plt.plot(x, y, c=\"grey\")\n",
        "            plt.plot(x, pred)\n",
        "            plt.fill_between(x, pred-std_pred, pred+std_pred, \n",
        "                            alpha=0.3, color='tab:blue', label='+/- std')\n",
        "            plt.scatter(self.x_samples, self.y_samples, c=\"orange\")\n",
        "            plt.legend([\"GT\", \"predicted mean\", \"predicted CI\", \"samples\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        elif self.problem.input_shape == 2:   # 2D domain\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "            ax.scatter(self.x_samples[:,0], self.x_samples[:,1], self.y_samples, color=\"orange\")\n",
        "            ax.scatter(x[:,0], x[:,1], y, alpha=0.15, color=\"lightgrey\")\n",
        "            ax.scatter(x[:,0], x[:,1], pred, alpha=0.3)\n",
        "            ax.scatter(x[:,0], x[:,1], pred-std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.scatter(x[:,0], x[:,1], pred+std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.view_init(elev=15, azim=60)\n",
        "            plt.legend([\"samples\", \"GT\", \"predicted mean\", \"predicted CI\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Plot not available for high dimensional domains.\")\n",
        "            print(f\"X:\\n{self.x_samples}\\nY:\\n{self.y_samples}\")\n",
        "\n",
        "    def run(self):\n",
        "        for iteration in range(self.iterations):\n",
        "            print(f\"Iteration {iteration}:\", \"=\"*20)\n",
        "            optimizer = tfa.optimizers.AdamW(weight_decay=self.weight_decay,\n",
        "                                             learning_rate=self.lr)\n",
        "            keras_mdl = build_probabilistic_regressor(\n",
        "                self.problem.input_shape, self.depth, self.width)\n",
        "            keras_mdl.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "            keras_mdl.summary()\n",
        "\n",
        "            train_time = time.time()\n",
        "            keras_mdl, hstory = self.train(keras_mdl)\n",
        "            train_time = time.time() - train_time\n",
        "\n",
        "            self.plot(hstory, keras_mdl)\n",
        "\n",
        "            solver_time = time.time()\n",
        "            sol = self.solver_optimization(keras_mdl)\n",
        "            solver_time = time.time() - solver_time\n",
        "\n",
        "            if sol is None:\n",
        "                print(f'Not feasible')\n",
        "                break\n",
        "            sol.solve_details.print_information()\n",
        "\n",
        "            opt_x = np.zeros(self.problem.input_shape)\n",
        "            for i in range(self.problem.input_shape):\n",
        "                opt_x[i] = sol[\"x\"+str(i)]\n",
        "            opt_x = self.reverse_normalize_X(opt_x)\n",
        "            opt_y = self.problem.fun(opt_x)\n",
        "            \n",
        "            emean = self.reverse_normalize_Y(sol['out_mean'])\n",
        "            print(f\"opt input={opt_x}, expected mean={emean}, gt={opt_y}\")\n",
        "            print(f\"train time: {train_time}, solver time: {solver_time}\")\n",
        "\n",
        "            self.x_samples = np.concatenate((self.x_samples, np.expand_dims(opt_x, 0)))\n",
        "            self.y_samples = np.append(self.y_samples, opt_y)\n",
        "\n",
        "            if iteration == 0 and ENABLE_WANDB: # log starting points before the first iteration\n",
        "                for j in range(self.starting_points):\n",
        "                    wandb.log({\"x_sample\": self.x_samples[j], \"y_sample\": self.y_samples[j]})\n",
        "                \n",
        "            self.solution_log(sol)\n",
        "\n",
        "            if ENABLE_WANDB: \n",
        "                wandb.log({\n",
        "                    \"train_predictions\": wandb.Image('chart.png'), \n",
        "                    \"train_loss\": wandb.Image('train_loss.png'),\n",
        "                    \"x_sample\": opt_x, \"y_sample\": opt_y, \n",
        "                    \"train_time\": train_time, \"solver_time\": solver_time\n",
        "                })\n",
        "                \n",
        "        print(f\"Min found: {np.min(self.y_samples)} in {np.argmin(self.y_samples)+1-self.starting_points} iterations\")\n",
        "        if ENABLE_WANDB:\n",
        "            wandb.log({\n",
        "                \"min_found\": np.min(self.y_samples),\n",
        "                \"n_iterations\": np.argmin(self.y_samples)+1-self.starting_points\n",
        "            })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "sEFhpl6xi54I"
      },
      "source": [
        "#@title Base UCB\n",
        "\n",
        "class BaseUCBExperiment(BaseExperiment):\n",
        "\n",
        "    def __init__(self, beta_ucb, *args, **kwargs):\n",
        "        super(BaseUCBExperiment, self).__init__(*args, **kwargs)\n",
        "        self.beta = beta_ucb\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        print(\"UCB solver...\")\n",
        "        cplex = cpx.Model()\n",
        "        bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "        parsed_mdl = parse_tfp(keras_mdl)\n",
        "        propagate_bound(parsed_mdl, [[0,1]]*self.problem.input_shape)\n",
        "        xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                   self.problem.input_type,\n",
        "                                   [[0,1]]*self.problem.input_shape)\n",
        "\n",
        "        stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "        ucb_lb = -yvars[0].ub + self.beta * stddev.lb\n",
        "        ucb_ub = -yvars[0].lb + self.beta * stddev.ub\n",
        "        print(\"UCB bounds:\", ucb_lb, ucb_ub)\n",
        "        ucb = cplex.continuous_var(lb=ucb_lb, ub=ucb_ub, name=\"ucb\")\n",
        "        ucb = -yvars[0] + self.beta * stddev\n",
        "\n",
        "        # Problem contraints\n",
        "        if self.problem.constraint_cb is not None:\n",
        "            rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "            self.problem.constraint_cb(self, cplex, rev_norm_xvars)\n",
        "        \n",
        "        cplex.set_objective('max', ucb)\n",
        "        cplex.set_time_limit(self.solver_timeout)\n",
        "        sol = cplex.solve()\n",
        "\n",
        "        print(cplex.solve_details)\n",
        "        cplex.print_information()\n",
        "        return sol\n",
        "\n",
        "    def solution_log(self, solution):\n",
        "        print(f\"UCB: {solution['ucb']}\")\n",
        "        if ENABLE_WANDB: \n",
        "            wandb.log({\n",
        "                \"ucb\": solution['ucb']\n",
        "            }, commit=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "3WyQS_G2ejql"
      },
      "source": [
        "#@title EarlyStop\n",
        "\n",
        "class EarlyStop(BaseUCBExperiment):\n",
        "\n",
        "    def __init__(self, patience, eval_points, *args, **kwargs):\n",
        "        super(EarlyStop, self).__init__(*args, **kwargs)\n",
        "        self.eval_points = eval_points\n",
        "        self.x_val, self.y_val = self.problem.get_dataset(self.eval_points)\n",
        "        self.x_val = self.normalize_X(self.x_val)\n",
        "        self.y_val = self.normalize_Y(self.y_val)\n",
        "        self.cb = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
        "                                                    patience=patience, restore_best_weights=True)]\n",
        "        \n",
        "    def train(self, keras_mdl):\n",
        "        print(\"Early stop training...\")\n",
        "        bs = self.batch_size if self.batch_size else self.x_samples.shape[0]\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        norm_y = self.normalize_Y(self.y_samples)\n",
        "\n",
        "        hstory = keras_mdl.fit(norm_x, norm_y, \n",
        "                               validation_data=(self.x_val, self.y_val),\n",
        "                               batch_size=bs, epochs=self.epochs, \n",
        "                               verbose=0, callbacks=self.cb)\n",
        "\n",
        "        return keras_mdl, hstory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "UqLsO46NeTmX"
      },
      "source": [
        "#@title Stop CI\n",
        "\n",
        "class StopCICB(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, x_val, threshold, *args, **kwargs):\n",
        "        super(StopCICB, self).__init__(*args, **kwargs)\n",
        "        self.x_val = x_val\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        prob_pred = self.model(self.x_val)\n",
        "        std_pred = prob_pred.stddev().numpy().ravel()\n",
        "        if epoch % 100 == 0:\n",
        "            print(epoch, \"mean stddev\", np.mean(std_pred))\n",
        "        if np.mean(std_pred) < self.threshold:\n",
        "            print(\"break condition on epoch\", epoch, \"with mean stddev\", np.mean(std_pred))\n",
        "            self.model.stop_training = True\n",
        "\n",
        "class StopCI(BaseUCBExperiment):\n",
        "\n",
        "    def __init__(self, eval_points, ci_threshold, *args, **kwargs):\n",
        "        super(StopCI, self).__init__(*args, **kwargs)\n",
        "        self.eval_points = eval_points\n",
        "        self.ci_threshold = ci_threshold\n",
        "        val = self.problem.get_dataset(self.eval_points)[0]\n",
        "        val = self.normalize_X(val)\n",
        "        stop_ci = StopCICB(val, self.ci_threshold)\n",
        "        self.cb = [stop_ci]\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        print(\"Stop CI training...\")\n",
        "        bs = self.batch_size if self.batch_size else self.x_samples.shape[0]\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        norm_y = self.normalize_Y(self.y_samples)\n",
        "\n",
        "        hstory = keras_mdl.fit(norm_x, norm_y,\n",
        "                batch_size=bs, epochs=self.epochs, verbose=0, callbacks=self.cb)\n",
        "\n",
        "        return keras_mdl, hstory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "XtcmHVARg7PJ"
      },
      "source": [
        "#@title AugmentUniform\n",
        "\n",
        "class AugmentUniform(StopCI):\n",
        "\n",
        "    def __init__(self, num_aug, *args, **kwargs):\n",
        "        super(AugmentUniform, self).__init__(*args, **kwargs)\n",
        "        self.num_aug = num_aug\n",
        "        self.x_aug_samples = None\n",
        "        self.y_aug_samples = None\n",
        "\n",
        "    def plot(self, hstory, keras_mdl):\n",
        "        if self.problem.input_shape <= 2:\n",
        "            x,y = self.problem.get_grid(100)\n",
        "            prob_pred = keras_mdl(self.normalize_X(x))\n",
        "            pred = prob_pred.mean().numpy().ravel()\n",
        "            pred = self.reverse_normalize_Y(pred)\n",
        "            std_pred = prob_pred.stddev().numpy().ravel()\n",
        "            std_pred = self.reverse_normalize_Y(std_pred, stddev=True)\n",
        "\n",
        "        plt.plot(hstory.history[\"loss\"])\n",
        "        plt.savefig('train_loss.png')\n",
        "        plt.show()\n",
        "\n",
        "        fig = plt.figure(figsize=(15,10))\n",
        "        if self.problem.input_shape == 1:   # 1D domain\n",
        "            plt.xlim(self.problem.input_bounds[0])\n",
        "            x = np.squeeze(x)\n",
        "            plt.plot(x, y, c=\"grey\")\n",
        "            plt.plot(x, pred)\n",
        "            plt.fill_between(x, pred-std_pred, pred+std_pred, \n",
        "                            alpha=0.3, color='tab:blue', label='+/- std')\n",
        "            plt.scatter(self.x_aug_samples, self.y_aug_samples, c=\"grey\")\n",
        "            plt.scatter(self.x_samples, self.y_samples, c=\"orange\")\n",
        "            plt.legend([\"GT\", \"predicted mean\", \"predicted CI\", \"samples\", \"augmented samples\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        elif self.problem.input_shape == 2:    # 2D domain\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "            ax.scatter(x[:,0], x[:,1], y, alpha=0.15, color=\"lightgrey\")\n",
        "            ax.scatter(self.x_aug_samples[:,0], self.x_aug_samples[:,1], self.y_aug_samples, c=\"grey\", alpha=0.3)\n",
        "            ax.scatter(self.x_samples[:,0], self.x_samples[:,1], self.y_samples, color=\"orange\", alpha=1)\n",
        "            ax.scatter(x[:,0], x[:,1], pred)\n",
        "            ax.scatter(x[:,0], x[:,1], pred-std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.scatter(x[:,0], x[:,1], pred+std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.view_init(elev=15, azim=60)\n",
        "            plt.legend([\"samples\", \"augmented samples\", \"predicted mean\", \"predicted CI\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Plot not available for high dimensional domains.\")\n",
        "            print(f\"X:\\n{self.x_samples}\\nY:\\n{self.y_samples}\")\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        print(\"Uniform augmented training...\")\n",
        "        self.x_aug_samples = np.concatenate((self.x_samples, \n",
        "                                        self.problem.get_dataset(self.num_aug)[0]))\n",
        "        y_range = np.max(np.abs(self.y_samples))*2                              \n",
        "        self.y_aug_samples = np.concatenate((self.y_samples, \n",
        "                                        (np.random.rand(self.num_aug)-0.5)*y_range))  \n",
        "\n",
        "        sw = np.ones_like(self.x_aug_samples)  \n",
        "        sw[:self.x_samples.shape[0]] = self.num_aug*2\n",
        "\n",
        "        bs = self.batch_size if self.batch_size else self.x_aug_samples.shape[0]\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_aug_samples)\n",
        "        norm_y = self.normalize_Y(self.y_aug_samples)\n",
        "\n",
        "        hstory = keras_mdl.fit(norm_x, norm_y,\n",
        "            batch_size=bs, epochs=self.epochs, verbose=0, callbacks=self.cb, sample_weight=sw)\n",
        "        \n",
        "        return keras_mdl, hstory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "z62pqvO7hmhU"
      },
      "source": [
        "#@title LHS\n",
        "\n",
        "class LHS(AugmentUniform):\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        print(\"LHS augmented training\")\n",
        "        n_datapoint = self.num_aug ** self.problem.input_shape\n",
        "\n",
        "        aug_x = self.problem.get_grid(self.num_aug)[0]\n",
        "        aug_x = np.concatenate((aug_x, aug_x))\n",
        "\n",
        "        y_range = np.max(np.abs(self.y_samples))*2                              \n",
        "        aug_y = np.concatenate(((np.random.rand(n_datapoint)-0.5)*y_range,\n",
        "                                (np.random.rand(n_datapoint)-0.5)*y_range))\n",
        "        self.x_aug_samples = np.concatenate((self.x_samples, aug_x))\n",
        "        self.y_aug_samples = np.concatenate((self.y_samples, aug_y))\n",
        "\n",
        "        sw = np.ones_like(self.x_aug_samples)  \n",
        "        sw[:self.x_samples.shape[0]] = n_datapoint\n",
        "\n",
        "        bs = self.batch_size if self.batch_size else self.x_aug_samples.shape[0]\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_aug_samples)\n",
        "        norm_y = self.normalize_Y(self.y_aug_samples)\n",
        "\n",
        "        hstory = keras_mdl.fit(norm_x, norm_y,\n",
        "            batch_size=bs, epochs=self.epochs, verbose=0, callbacks=self.cb, sample_weight=sw)\n",
        "        \n",
        "        return keras_mdl, hstory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "k9nJMUn8mox3"
      },
      "source": [
        "#@title MILP dist\n",
        "\n",
        "class PWLMILPDist(StopCI):\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        print(\"Distance based UCB solver...\")\n",
        "        cplex = cpx.Model()\n",
        "        bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "        parsed_mdl = parse_tfp(keras_mdl)\n",
        "        propagate_bound(parsed_mdl, [[0,1]]*self.problem.input_shape)\n",
        "        xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                   self.problem.input_type,\n",
        "                                   [[0,1]]*self.problem.input_shape)\n",
        "\n",
        "        stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        dist = pwl_sample_dist(bkd, cplex, xvars, norm_x, \n",
        "                               self.problem.input_type,\n",
        "                               [[0,1]]*self.problem.input_shape, \n",
        "                               nnodes = min(20, self.x_samples.shape[0]))\n",
        "\n",
        "        ucb_lb = -yvars[0].ub + self.beta * (stddev.lb + dist.lb)\n",
        "        ucb_ub = -yvars[0].lb + self.beta * (stddev.ub + dist.ub)\n",
        "        ucb = cplex.continuous_var(lb=ucb_lb, ub=ucb_ub, name=\"ucb\")\n",
        "        ucb = -yvars[0] + self.beta * (stddev + dist)\n",
        "        #ucb = cplex.continuous_var(lb=-cplex.infinity, ub=cplex.infinity, name=\"ucb\")\n",
        "        #cplex.add_constraint(ucb == -yvars[0] + self.beta * (stddev + dist))\n",
        "\n",
        "        # Problem contraints\n",
        "        if self.problem.constraint_cb is not None:\n",
        "            rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "            self.problem.constraint_cb(self, cplex, rev_norm_xvars)\n",
        "\n",
        "        cplex.set_objective('max', ucb)\n",
        "        cplex.set_time_limit(self.solver_timeout)\n",
        "        sol = cplex.solve()\n",
        "        \n",
        "        #print(\"UCB bounds:\", ucb_lb, ucb_ub)\n",
        "        #print(\"beta\", self.beta)\n",
        "        #print(\"stdout\", sol['exp_out'])\n",
        "        #print(\"mean\", sol['out_mean'])\n",
        "        #print(\"distout\", sol['dist_out'])\n",
        "        #print(norm_x)\n",
        "\n",
        "        print(cplex.solve_details)\n",
        "        cplex.print_information()\n",
        "        return sol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Tv2QdDXOnwW5"
      },
      "source": [
        "#@title Hybrid\n",
        "\n",
        "class Hybrid(PWLMILPDist, AugmentUniform):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "FAQnPOZmByXx"
      },
      "source": [
        "#@title FastMILP dist\n",
        "\n",
        "class FastMILPDist(StopCI):\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        print(\"Distance based UCB solver...\")\n",
        "        cplex = cpx.Model()\n",
        "        bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "        parsed_mdl = parse_tfp(keras_mdl)\n",
        "        propagate_bound(parsed_mdl, [[0,1]]*self.problem.input_shape)\n",
        "        xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                   self.problem.input_type,\n",
        "                                   [[0,1]]*self.problem.input_shape)\n",
        "\n",
        "        stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "        # Distance\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        dist_ub = self.problem.input_shape # hack: max dist = sum(bounds) \n",
        "        dist = cplex.continuous_var(lb=0, ub=dist_ub, name=\"dist\")\n",
        "        for row in range(norm_x.shape[0]):\n",
        "            sd = 0\n",
        "            for feature in range(norm_x.shape[1]):\n",
        "                #sd += (norm_x[row, feature] - xvars[feature]) * (norm_x[row, feature] - xvars[feature]) # NOTE: non-convex\n",
        "                sd += cplex.abs(norm_x[row, feature] - xvars[feature])\n",
        "            cplex.add_constraint(sd*self.problem.input_shape >= dist)  # scale down the l1 dist with dimensions\n",
        "\n",
        "        # UCB\n",
        "        ucb_lb = -yvars[0].ub + self.beta * (stddev.lb + dist.lb)\n",
        "        ucb_ub = -yvars[0].lb + self.beta * (stddev.ub + dist.ub)\n",
        "        ucb = cplex.continuous_var(lb=ucb_lb, ub=ucb_ub, name=\"ucb\")\n",
        "        ucb = -yvars[0] + self.beta * (stddev + dist)\n",
        "        #ucb = cplex.continuous_var(lb=-cplex.infinity, ub=cplex.infinity, name=\"ucb\")\n",
        "        #cplex.add_constraint(ucb == -yvars[0] + self.beta * (stddev + dist))\n",
        "\n",
        "        # Problem contraints\n",
        "        if self.problem.constraint_cb is not None:\n",
        "            rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "            self.problem.constraint_cb(self, cplex, rev_norm_xvars)\n",
        "\n",
        "        cplex.set_objective('max', ucb)\n",
        "        cplex.set_time_limit(self.solver_timeout)\n",
        "        sol = cplex.solve()\n",
        "        \n",
        "        #cplex.prettyprint()\n",
        "        #print(\"UCB bounds:\", ucb_lb, ucb_ub)\n",
        "        print(\"==== dist\", sol['dist'])\n",
        "\n",
        "        print(cplex.solve_details)\n",
        "        cplex.print_information()\n",
        "        return sol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIUvAeW-hUwG"
      },
      "source": [
        "#@title â˜¢ï¸ Beta decay\n",
        "\n",
        "class BetaDecay(StopCI):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(BetaDecay, self).__init__(*args, **kwargs)\n",
        "        self.iter = 1\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        print(\"Distance based UCB solver...\")\n",
        "        cplex = cpx.Model()\n",
        "        bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "        parsed_mdl = parse_tfp(keras_mdl)\n",
        "        propagate_bound(parsed_mdl, [[0,1]]*self.problem.input_shape)\n",
        "        xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                   self.problem.input_type,\n",
        "                                   [[0,1]]*self.problem.input_shape)\n",
        "\n",
        "        stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "        # Distance\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        dist_ub = self.problem.input_shape #hack\n",
        "        dist = cplex.continuous_var(lb=0, ub=dist_ub, name=\"dist\")\n",
        "        for row in range(norm_x.shape[0]):\n",
        "            sd = 0\n",
        "            for feature in range(norm_x.shape[1]):\n",
        "                #sd += (norm_x[row, feature] - xvars[feature]) * (norm_x[row, feature] - xvars[feature])\n",
        "                sd += cplex.abs(norm_x[row, feature] - xvars[feature])\n",
        "            cplex.add_constraint(sd*self.problem.input_shape >= dist)  # scale down the l1 dist with dimensions\n",
        "\n",
        "        # Beta decay\n",
        "        #current_beta = self.beta * math.pow(self.iter, -1/3)\n",
        "        current_beta = self.beta * (-self.iter/ITERATIONS + 1 + 1/ITERATIONS)\n",
        "\n",
        "        # UCB\n",
        "        ucb_lb = -yvars[0].ub + current_beta * (stddev.lb + dist.lb)\n",
        "        ucb_ub = -yvars[0].lb + current_beta * (stddev.ub + dist.ub)\n",
        "        ucb = cplex.continuous_var(lb=ucb_lb, ub=ucb_ub, name=\"ucb\")\n",
        "        ucb = -yvars[0] + current_beta * (stddev + dist)\n",
        "        #ucb = cplex.continuous_var(lb=-cplex.infinity, ub=cplex.infinity, name=\"ucb\")\n",
        "        #cplex.add_constraint(ucb == -yvars[0] + current_beta * (stddev + dist))\n",
        "\n",
        "        # Problem contraints\n",
        "        if self.problem.constraint_cb is not None:\n",
        "            rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "            self.problem.constraint_cb(self, cplex, rev_norm_xvars)\n",
        "\n",
        "        cplex.set_objective('max', ucb)\n",
        "        cplex.set_time_limit(self.solver_timeout)\n",
        "        sol = cplex.solve()\n",
        "        \n",
        "        #cplex.prettyprint()\n",
        "        #print(\"UCB bounds:\", ucb_lb, ucb_ub)\n",
        "        print(\"==== beta\", current_beta)\n",
        "        print(\"==== dist\", sol['dist'])\n",
        "\n",
        "        self.iter += 1\n",
        "        print(cplex.solve_details)\n",
        "        cplex.print_information()\n",
        "        return sol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW0oUNuGetvq"
      },
      "source": [
        "# ðŸš€ Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IywTUKNLocnX",
        "cellView": "code"
      },
      "source": [
        "#@title ðŸŽ¯ Targets\n",
        "\n",
        "# Functions\n",
        "################################################################################\n",
        "\n",
        "def fun_polynomial(x):\n",
        "    return 0.5*(0.1*math.pow(5*x-1, 4) - 0.4*math.pow(5*x-1, 3) + 0.5*(5*x-1))\n",
        "\n",
        "def fun_ackley(x):\n",
        "    x1,x2 = x[0]-1,x[1]-2   # center in 1,2 to remove the 0 bias of nn\n",
        "    return -20*math.exp(-0.2*math.sqrt(0.5*(x1*x1+x2*x2))) - \\\n",
        "        math.exp(0.5*(math.cos(2*math.pi*x1)+math.cos(2*math.pi*x2))) + \\\n",
        "        math.e + 20\n",
        "\n",
        "def fun_mccormick(x):\n",
        "    x1,x2 = x[0],x[1]\n",
        "    return math.sin(x1+x2) + math.pow(x1-x2,2)-1.5*x1+2.5*x2+1\n",
        "\n",
        "def build_rosenbrock(rosenbrock_dim):\n",
        "    def f(x):\n",
        "        y=0\n",
        "        for i in range(rosenbrock_dim-1):\n",
        "            y+= 100 * math.pow(x[i+1] - x[i]*x[i], 2) + math.pow(1-x[i], 2)\n",
        "        return y\n",
        "    vtypes = [\"real\"]*rosenbrock_dim\n",
        "    bounds = [[-2, 2]]*rosenbrock_dim\n",
        "    return f, vtypes, bounds\n",
        "\n",
        "# Constraints \n",
        "################################################################################\n",
        "\n",
        "def cst_disk(experiment, cplex, xvars):     # x1^2 + x2^2 < r^2\n",
        "    x1,x2 = xvars\n",
        "    center = [1,2]\n",
        "    r = 0.5\n",
        "    x1 -= center[0]\n",
        "    x2 -= center[1]\n",
        "    cplex.add_constraint(x1*x1 + x2*x2 <= r*r)\n",
        "\n",
        "def cst_sphere(experiment, cplex, xvars):     # x1^2 + x2^2 + x3^2 < r^2\n",
        "    x1,x2,x3 = xvars\n",
        "    center = [-1,0.5,0.6]\n",
        "    r = 1.2\n",
        "    x1 -= center[0]\n",
        "    x2 -= center[1]\n",
        "    x3 -= center[2]\n",
        "    cplex.add_constraint(x1*x1 + x2*x2 + x3*x3 <= r*r)\n",
        "\n",
        "def cst_leq(experiment, cplex, xvars):     # x1 < x2\n",
        "    x1,x2 = xvars\n",
        "    cplex.add_constraint(x1 <= x2)\n",
        "\n",
        "# Problems\n",
        "################################################################################\n",
        "\n",
        "PROBLEM_POLYNOMIAL = Problem(\"polynomial\", \n",
        "                             fun_polynomial, \n",
        "                             [\"real\"],\n",
        "                             [[0, 1]])\n",
        "\n",
        "PROBLEM_ACKLEY = Problem(\"ackley\", \n",
        "                         fun_ackley, \n",
        "                         [\"real\", \"real\"],\n",
        "                         [[-3, 3], [-3, 3]])\n",
        "\n",
        "PROBLEM_CST_ACKLEY = Problem(\"constrained_ackley\", \n",
        "                             fun_ackley, \n",
        "                             [\"real\", \"real\"],\n",
        "                             [[-3, 3], [-2, 2]], \n",
        "                             cst_disk)\n",
        "\n",
        "PROBLEM_INT_ACKLEY = Problem(\"int_ackley\", \n",
        "                             fun_ackley, \n",
        "                             [\"int\", \"real\"],\n",
        "                             [[-3, 3], [-2, 2]],\n",
        "                             cst_leq)\n",
        "\n",
        "PROBLEM_MCCORMICK = Problem(\"mccormick\", \n",
        "                            fun_mccormick, \n",
        "                            [\"real\", \"real\"],\n",
        "                            [[-1.5, 4], [-3, 4]])\n",
        "\n",
        "PROBLEM_ROSENBROCK2D = Problem(\"rosenbrock2D\", *build_rosenbrock(2))\n",
        "PROBLEM_ROSENBROCK3D = Problem(\"rosenbrock3D\", *build_rosenbrock(3))\n",
        "PROBLEM_ROSENBROCK4D = Problem(\"rosenbrock4D\", *build_rosenbrock(4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3k-S4lGbtIu",
        "cellView": "form"
      },
      "source": [
        "#@title ðŸ“ˆ Parameters and WandB\n",
        "\n",
        "ITERATIONS =                                  10#@param {type:\"integer\"}\n",
        "STARTING_POINTS =                              3#@param {type:\"integer\"}\n",
        "\n",
        "EPOCHS =                                    9999#@param {type:\"integer\"}    \n",
        "PATIENCE = 100                                   #@param {type:\"integer\"}\n",
        "EVAL_POINTS = 20                                   #@param {type:\"integer\"}\n",
        "LR =                                        1e-4#@param {type:\"number\"}\n",
        "WEIGHT_DECAY =                                        1e-4#@param {type:\"number\"}\n",
        "BATCH_SIZE = None                               #@param {type:\"raw\"} None = all samples in 1 batch\n",
        "DEPTH =                                        4#@param {type:\"integer\"}\n",
        "WIDTH =                                       20#@param {type:\"integer\"}\n",
        "\n",
        "BETA_UCB =                                     1#@param {type:\"number\"}\n",
        "\n",
        "AUG_POINTS =                                 20#@param {type:\"integer\"}\n",
        "\n",
        "SOLVER_TIMEOUT = 30                             #@param {type:\"integer\"}\n",
        "\n",
        "CI_THRESHOLD =              0.05#@param {type:\"number\"} \n",
        "\n",
        "# set if you plan to log on wandb\n",
        "ENABLE_WANDB = False                            #@param {type:\"boolean\"}        \n",
        "\n",
        "if ENABLE_WANDB and \"wandb\" not in sys.modules:\n",
        "    !pip install wandb > /dev/null\n",
        "    !wandb login\n",
        "    import wandb\n",
        "\n",
        "def init_wandb(experiment_name, run_id):\n",
        "    if run_id is not None: \n",
        "        wandb.init(project='eml', id=run_id, resume='allow')\n",
        "    else:\n",
        "        wandb.init(project='eml', name=experiment_name)\n",
        "\n",
        "        wandb.config.iterations = ITERATIONS\n",
        "        wandb.config.starting_points = STARTING_POINTS\n",
        "        wandb.config.epochs = EPOCHS\n",
        "        wandb.config.patience = PATIENCE\n",
        "        wandb.config.eval_points = EVAL_POINTS\n",
        "        wandb.config.lr = LR\n",
        "        wandb.config.weight_decay = WEIGHT_DECAY\n",
        "        wandb.config.batch_size = BATCH_SIZE\n",
        "        wandb.config.depth = DEPTH\n",
        "        wandb.config.width = WIDTH\n",
        "        wandb.config.beta_ucb = BETA_UCB\n",
        "        wandb.config.aug_points = AUG_POINTS\n",
        "        wandb.config.solver_timeout = SOLVER_TIMEOUT\n",
        "        wandb.config.ci_threshold = CI_THRESHOLD\n",
        "\n",
        "def run_experiment(name, target):\n",
        "    if name == \"BayesianOptimization\":\n",
        "        optimizer = bayesian_opt_gpy(target, ITERATIONS, STARTING_POINTS)\n",
        "        return optimizer\n",
        "        \n",
        "    if name == \"EarlyStop\":\n",
        "        instance = EarlyStop(\n",
        "            PATIENCE, EVAL_POINTS, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "        \n",
        "    if name == \"StopCI\":\n",
        "        instance = StopCI(\n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "        \n",
        "    if name == \"AugmentUniform\":\n",
        "        instance = AugmentUniform(\n",
        "            AUG_POINTS, \n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "        \n",
        "    if name == \"AugmentLHS\":\n",
        "        instance = LHS(\n",
        "            AUG_POINTS, \n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "        \n",
        "    if name == \"PWLMILPDist\":\n",
        "        instance = PWLMILPDist(\n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "        \n",
        "    if name == \"Hybrid\":\n",
        "        instance = Hybrid(\n",
        "            AUG_POINTS, \n",
        "            EVAL_POINTS, CI_THRESHOLD,\n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "\n",
        "    if name == \"FastMILPDist\":\n",
        "        instance = FastMILPDist(\n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "    \n",
        "    if name == \"BetaDecay\":\n",
        "        instance = BetaDecay(\n",
        "            EVAL_POINTS, CI_THRESHOLD, \n",
        "            BETA_UCB, \n",
        "            target, STARTING_POINTS, ITERATIONS, \n",
        "            EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "            SOLVER_TIMEOUT)\n",
        "        instance.run()\n",
        "        return instance\n",
        "\n",
        "    raise AttributeError(\"invalid method\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCI6spRykVDi",
        "cellView": "code"
      },
      "source": [
        "#@title â–¶ï¸ Run experiment\n",
        "\n",
        "# set if starting a new run\n",
        "EXPERIMENT_NAME = \"constraint_ackley\"      #@param {type:\"string\"}\n",
        "# set to None if starting a new run\n",
        "RUN_ID = None                                   #@param {type:\"raw\"}\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    init_wandb(EXPERIMENT_NAME, RUN_ID)\n",
        "\n",
        "INSTANCE = run_experiment(\"Hybrid\", PROBLEM_INT_ACKLEY)\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RSaRvzEkr_y",
        "cellView": "form"
      },
      "source": [
        "#@title â© Run all\n",
        "\n",
        "PROBLEMS = [\n",
        "    PROBLEM_POLYNOMIAL,\n",
        "    PROBLEM_ACKLEY,\n",
        "    PROBLEM_MCCORMICK,\n",
        "    PROBLEM_ROSENBROCK2D,\n",
        "    PROBLEM_ROSENBROCK3D,\n",
        "    PROBLEM_ROSENBROCK4D\n",
        "]\n",
        "\n",
        "EXPERIMENT_NAMES = [\n",
        "#   \"BayesianOptimization\",\n",
        "#    \"EarlyStop\",\n",
        "#    \"StopCI\",\n",
        "#    \"AugmentUniform\",\n",
        "#    \"AugmentLHS\",\n",
        "#    \"PWLMILPDist\",\n",
        "#    \"Hybrid\",\n",
        "    \"FastMILPDist\"\n",
        "]\n",
        "\n",
        "for p in PROBLEMS:\n",
        "    for e in EXPERIMENT_NAMES:\n",
        "        if ENABLE_WANDB:\n",
        "            init_wandb(f\"{p.name}_{e}\", None)\n",
        "        run_experiment(e, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2USqSnCBVDM"
      },
      "source": [
        "# ðŸ§ª Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C00w0zpdczA4"
      },
      "source": [
        "## Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZIHdcoXc6qR"
      },
      "source": [
        "def test_problem():\n",
        "    def f0(x):\n",
        "        return 0.5*(0.1*math.pow(5*x-1, 4) - 0.4*math.pow(5*x-1, 3) + 0.5*(5*x-1))\n",
        "    p0 = Problem(None, f0, [[0, 1]])\n",
        "\n",
        "    def f1(x):\n",
        "        x1,x2 = x[0],x[1]\n",
        "        return 10 * math.sin(x1) * math.sin(x2) \n",
        "    p1 = Problem(None, f1, [[-1, 1], [-1, 1]])\n",
        "\n",
        "    def ackley_fun(x):\n",
        "        x1,x2 = x[0],x[1]\n",
        "        return -20*math.exp(-0.2*math.sqrt(0.5*(x1*x1+x2*x2))) - \\\n",
        "            math.exp(0.5*(math.cos(2*math.pi*x1)+math.cos(2*math.pi*x2))) + \\\n",
        "            math.e + 20\n",
        "    ackley_problem = Problem(None, ackley_fun, [[-3, 3], [-3, 3]])\n",
        "\n",
        "    print(\"f0 grid\")\n",
        "    g0 = p0.get_grid(10)\n",
        "    x0, y0 = g0[0], g0[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot()\n",
        "    ax.scatter(x0, y0)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"f1 grid\")\n",
        "    g1 = p1.get_grid(10)\n",
        "    x1, y1 = g1[0], g1[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.scatter(x1[:,0], x1[:,1], y1)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"ackley grid\")\n",
        "    g1 = ackley_problem.get_grid(100)\n",
        "    x1, y1 = g1[0], g1[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.scatter(x1[:,0], x1[:,1], y1)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"f0 dataset\")\n",
        "    d0 = p0.get_dataset(10)\n",
        "    x0, y0 = d0[0], d0[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot()\n",
        "    ax.scatter(x0, y0)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"f1 dataset\")\n",
        "    d1 = p1.get_dataset(100)\n",
        "    x1, y1 = d1[0], d1[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.scatter(x1[:,0], x1[:,1], y1)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"ackley dataset\")\n",
        "    d1 = ackley_problem.get_dataset(10000)\n",
        "    x1, y1 = d1[0], d1[1]\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.scatter(x1[:,0], x1[:,1], y1)\n",
        "    plt.show()\n",
        "    \n",
        "test_problem()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbgkjkyrII_"
      },
      "source": [
        "##TFP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "nOEy-I0YLVfG"
      },
      "source": [
        "#@title Whole train set\n",
        "\n",
        "def tfp_test1():\n",
        "    set_seed()\n",
        "\n",
        "    p = Problem(None, polynomial_fun, [[0, 1]])\n",
        "    x,y = p.get_dataset(100)\n",
        "    x, y = x.ravel(), y.ravel()\n",
        "    x_train, y_train = x[:80], y[:80]\n",
        "    x_val, y_val = x[80:], y[80:]\n",
        "\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "    cb = [tf.keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)]\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "    bs = x_train.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
        "            batch_size=bs, epochs=5000, verbose=1, callbacks=cb)\n",
        "\n",
        "    sorted = x_val.argsort()\n",
        "    plot_prob_predictions(mdl_prob, x_val[sorted], y_val[sorted])\n",
        "\n",
        "tfp_test1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "hEFazkyhSjwD"
      },
      "source": [
        "#@title Few points linear\n",
        "\n",
        "def tfp_test2():\n",
        "    set_seed()\n",
        "\n",
        "    x_samples = np.random.rand(5)\n",
        "    y_samples = x_samples\n",
        "\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    bs = x_samples.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_samples, y_samples,\n",
        "            batch_size=bs, epochs=1000, verbose=1)\n",
        "\n",
        "    sorted = x_samples.argsort()\n",
        "    plot_prob_predictions(mdl_prob, x_samples[sorted], y_samples[sorted])\n",
        "\n",
        "tfp_test2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "NuesUNvAV9HX"
      },
      "source": [
        "#@title Different variance\n",
        "\n",
        "def tfp_test3():\n",
        "    set_seed()\n",
        "\n",
        "    points = np.random.rand(50)\n",
        "    noise = np.random.rand(20) / 5\n",
        "    x_samples = points\n",
        "    y_samples = np.copy(x_samples)\n",
        "    sorted_idx = x_samples.argsort()\n",
        "    y_samples[sorted_idx[:20]] += noise\n",
        "\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    bs = x_samples.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_samples, y_samples,\n",
        "            batch_size=bs, epochs=1000, verbose=1)\n",
        "\n",
        "    sorted = x_samples.argsort()\n",
        "    plot_prob_predictions(mdl_prob, x_samples[sorted], y_samples[sorted])\n",
        "\n",
        "tfp_test3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1WCq0t24LeC"
      },
      "source": [
        "## EML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Sv7hOKdHgMlz"
      },
      "source": [
        "#@title Minimize cost_fn\n",
        "\n",
        "def eml_test1():\n",
        "    #train\n",
        "    p = Problem(None, polynomial_fun, [[0, 1]])\n",
        "    x,y = p.get_dataset(100)\n",
        "    x, y = x.ravel(), y.ravel()\n",
        "    x_train, y_train = x[:80], y[:80]\n",
        "    x_val, y_val = x[80:], y[80:]\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "    cb = [tf.keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)]\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    bs = x_train.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
        "            batch_size=bs, epochs=5000, verbose=0, callbacks=cb)\n",
        "    \n",
        "    #solve\n",
        "    cplex = cpx.Model()\n",
        "    bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "    parsed_mdl = parse_tfp(mdl_prob)\n",
        "    propagate_bound(parsed_mdl, [[0,1]])\n",
        "    xvars, yvars = embed_model(bkd, cplex, parsed_mdl, [[0,1]])\n",
        "\n",
        "    cplex.set_objective('min', yvars[0])\n",
        "    cplex.set_time_limit(30)\n",
        "\n",
        "    sol = cplex.solve()\n",
        "\n",
        "    print(f'feasible: {sol is not None}')\n",
        "    print(cplex_backend.model_to_string(cplex))\n",
        "    print(sol.display())\n",
        "\n",
        "    opt_x = sol.get_value(\"x0\")\n",
        "    opt_mean = sol.get_value(\"out_mean\")\n",
        "    opt_std = math.pow(math.e, sol.get_value(\"out_std\"))\n",
        "    print(opt_x, opt_mean, opt_std)\n",
        "\n",
        "    dist = mdl_prob(np.array([[opt_x]]))\n",
        "    assert dist.mean() - opt_mean < 1e-6\n",
        "    assert dist.stddev() - opt_std < 1e-6\n",
        "\n",
        "eml_test1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "DXFInxIfr-6F"
      },
      "source": [
        "#@title Test pwl\n",
        "\n",
        "def eml_test2():\n",
        "    cplex = cpx.Model()\n",
        "    bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "    inp = cplex.continuous_var(lb=0, ub=1, name=\"test_in\")\n",
        "    out = pwl_normal_pdf(bkd, cplex, inp, nnodes=11)\n",
        "    cplex.set_objective('max', out)\n",
        "    cplex.set_time_limit(30)\n",
        "\n",
        "    cplex.prettyprint()\n",
        "    sol = cplex.solve()\n",
        "    print(f'feasible: {sol is not None}')\n",
        "    print(sol)\n",
        "\n",
        "    assert sol.get_value(\"test_in\") == 0\n",
        "\n",
        "eml_test2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "jinmrHST7m0G"
      },
      "source": [
        "#@title Minimize EI (non convex error)\n",
        "\n",
        "#   imp = mu - opt_mean - 0.1\n",
        "#   Z = imp / var\n",
        "#   ei = imp * norm.cdf(Z) + var * norm.pdf(Z)\n",
        "\n",
        "def eml_test3():\n",
        "    #train\n",
        "    p = Problem(None, polynomial_fun, [[0, 1]])\n",
        "    x,y = p.get_dataset(100)\n",
        "    x, y = x.ravel(), y.ravel()\n",
        "    x_train, y_train = x[:80], y[:80]\n",
        "    x_val, y_val = x[80:], y[80:]\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "    cb = [tf.keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)]\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    bs = x_train.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
        "            batch_size=bs, epochs=5000, verbose=0, callbacks=cb)\n",
        "    \n",
        "    #solve\n",
        "    epsilon = 0.1\n",
        "    cplex = cpx.Model()\n",
        "    bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "    parsed_mdl = parse_tfp(mdl_prob)\n",
        "    propagate_bound(parsed_mdl)\n",
        "    xvars, yvars = embed_model(bkd, cplex, parsed_mdl)\n",
        "\n",
        "    # EI\n",
        "    # find min mean (max improvement)\n",
        "    cplex.set_objective('min', yvars[0])\n",
        "    cplex.set_time_limit(30)\n",
        "    sol = cplex.solve()\n",
        "    print(f'feasible: {sol is not None}')\n",
        "    if sol:\n",
        "        opt_x = sol.get_value(\"in\")\n",
        "        opt_mean = sol.get_value(\"out_mean\")\n",
        "        opt_std = math.pow(math.e, sol.get_value(\"out_std\"))\n",
        "        print(opt_x, opt_mean, opt_std)\n",
        "\n",
        "    # compute ei\n",
        "    epsilon = 0.1\n",
        "    cplex = cpx.Model()\n",
        "    bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "    parsed_mdl = parse_tfp(mdl_prob)\n",
        "    propagate_bound(parsed_mdl, [[0,1]])\n",
        "    xvars, yvars = embed_model(bkd, cplex, parsed_mdl, [[0,1]])\n",
        "\n",
        "    imp = yvars[0] - opt_mean - epsilon\n",
        "    stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=11)\n",
        "    Z = cplex.continuous_var(lb=-cplex.infinity, ub=cplex.infinity, name=\"Z\")\n",
        "    cplex.add_constraint(Z * stddev == imp) # Z = imp / exp(yvars[1])\n",
        "    ncdf = pwl_normal_cdf(bkd, cplex, Z, nnodes=11)\n",
        "    npdf = pwl_normal_pdf(bkd, cplex, Z, nnodes=11)\n",
        "    ei = imp * ncdf + stddev * npdf\n",
        "    cplex.set_objective('min', ei)\n",
        "\n",
        "    cplex.set_time_limit(30)\n",
        "    sol = cplex.solve()\n",
        "    print(f'feasible: {sol is not None}')\n",
        "    if sol:\n",
        "        opt_x = sol.get_value(\"x0\")\n",
        "    print(sol)\n",
        "\n",
        "eml_test3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "htzSCBgQ2ueh"
      },
      "source": [
        "#@title Minimize UCB\n",
        "\n",
        "def eml_test4():\n",
        "    #train\n",
        "    p = Problem(None, polynomial_fun, [[0, 1]])\n",
        "    x,y = p.get_dataset(100)\n",
        "    x, y = x.ravel(), y.ravel()\n",
        "    x_train, y_train = x[:80], y[:80]\n",
        "    x_val, y_val = x[80:], y[80:]\n",
        "    mdl_prob = build_probabilistic_regressor(1)\n",
        "    mdl_prob.summary()\n",
        "    cb = [tf.keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)]\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    bs = x_train.shape[0]\n",
        "    mdl_prob.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "    hstory = mdl_prob.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
        "            batch_size=bs, epochs=500, verbose=0, callbacks=cb)\n",
        "    \n",
        "    #solve\n",
        "    beta = 0.01\n",
        "    cplex = cpx.Model()\n",
        "    bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "    parsed_mdl = parse_tfp(mdl_prob)\n",
        "    propagate_bound(parsed_mdl, [[0,1]])\n",
        "    xvars, yvars = embed_model(bkd, cplex, parsed_mdl, [[0,1]])\n",
        "\n",
        "    ucb = cplex.continuous_var(lb=-cplex.infinity, ub=cplex.infinity, name=\"ucb\")\n",
        "    stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=11)\n",
        "    cplex.add_constraint(ucb == -yvars[0] + beta * stddev) # max -f = min f\n",
        "\n",
        "    cplex.set_objective('max', ucb)\n",
        "\n",
        "    cplex.set_time_limit(30)\n",
        "    sol = cplex.solve()\n",
        "    print(f'feasible: {sol is not None}')\n",
        "    if sol:\n",
        "        opt_x = sol.get_value(\"x0\")\n",
        "        print(sol)\n",
        "    return sol, cplex\n",
        "eml_test4()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}