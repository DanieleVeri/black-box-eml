{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz2foCh7eqQr"
      },
      "source": [
        "# EMLOpt\n",
        "Master Thesis in Artificial Intelligence at University of Bologna, a.y. 2021/2022\n",
        "\n",
        "Daniele Verì, Michele Lombardi, Andrea Borghesi, Stefano Teso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNNmQ5x5YJaS"
      },
      "source": [
        "# 📥 Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsM5SqajYG_V"
      },
      "outputs": [],
      "source": [
        "#@title CPLEX\n",
        "\n",
        "!wget https://api.wandb.ai/artifactsV2/gcp-us/veri/QXJ0aWZhY3Q6MjU1ODAzMjI=/69b1b89a73a7d0931fbfdb355eb147c3 -O cplex_studio1210.linux-x86-64.bin\n",
        "!wget https://api.wandb.ai/artifactsV2/gcp-us/veri/QXJ0aWZhY3Q6MjU1ODAzMjI=/97133b747b0114a4e3dba77ab26d68d5 -O response.properties\n",
        "\n",
        "!pip install docplex\n",
        "!sh cplex_studio1210.linux-x86-64.bin -f response.properties\n",
        "!python3 /opt/ibm/ILOG/CPLEX_Studio1210/python/setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPqw-nj0X3v"
      },
      "outputs": [],
      "source": [
        "#@title Tensorflow addons\n",
        "\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaPHqIopVAWW"
      },
      "outputs": [],
      "source": [
        "#@title EMLlib\n",
        "\n",
        "!git clone https://github.com/DanieleVeri/emllib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nsfFSUmkCr4"
      },
      "outputs": [],
      "source": [
        "#@title scikit-optimize\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcyNrxy43Bgb"
      },
      "source": [
        "# 📑 Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2SDDKf13x94"
      },
      "outputs": [],
      "source": [
        "#@title Base import and seed\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "if not 'emllib' in sys.path: sys.path.insert(1, 'emllib')\n",
        "\n",
        "import pickle\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "admZL6drfYtp"
      },
      "source": [
        "##Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "_X0Nzl3PeFAw"
      },
      "outputs": [],
      "source": [
        "#@title Problem class - quadratic + random slack\n",
        "\n",
        "import docplex.mp.model as cpx\n",
        "\n",
        "from skopt.sampler import Lhs\n",
        "from skopt.space import Space\n",
        "\n",
        "class ProblemQRS:\n",
        "\n",
        "    def __init__(self, name, fun, input_type, input_bounds, constraint_cb=None, stocasthic=False):\n",
        "        self.name = name\n",
        "        self.fun = fun\n",
        "        self.input_type = input_type\n",
        "        self.input_bounds = input_bounds\n",
        "        self.input_shape = len(self.input_bounds)\n",
        "        self.constraint_cb = constraint_cb\n",
        "        self.stocasthic = stocasthic\n",
        "\n",
        "    def get_dataset(self, n_points):\n",
        "        if self.constraint_cb is None:\n",
        "            x = np.random.rand(n_points, self.input_shape)\n",
        "            for i, b in enumerate(self.input_bounds):\n",
        "                lb = b[0]\n",
        "                ub = b[1]\n",
        "                if self.input_type[i] == \"int\":\n",
        "                    x[:,i] = np.random.randint(lb, high=ub, size=n_points)\n",
        "                else:\n",
        "                    x[:,i] *= ub - lb\n",
        "                    x[:,i] += lb\n",
        "            y = np.zeros((n_points))\n",
        "            for i in range(n_points):\n",
        "                y[i] = self.fun(x[i, :])\n",
        "            return x, y\n",
        "\n",
        "        # constrained dataset:\n",
        "        x = np.zeros((n_points, self.input_shape))\n",
        "        bounds = []\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            if self.input_type[i] == \"int\":\n",
        "                bounds.append((int(b[0]), int(b[1])))\n",
        "            else:\n",
        "                bounds.append((float(b[0]), float(b[1])))\n",
        "                \n",
        "        space = Space(bounds)\n",
        "        lhs = Lhs(lhs_type=\"classic\", criterion=None, iterations=1000)\n",
        "        lhs_samples = lhs.generate(space.dimensions, n_points)\n",
        "\n",
        "        p = 0\n",
        "        while True:\n",
        "            cplex = cpx.Model()\n",
        "            xvars = []\n",
        "            for i,b in enumerate(self.input_bounds):\n",
        "                if self.input_type[i] == \"int\":\n",
        "                    xvars.append(cplex.integer_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "                else:\n",
        "                    xvars.append(cplex.continuous_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "            \n",
        "            csts = self.constraint_cb(cplex, xvars)\n",
        "            # add slack\n",
        "            avg_range = np.mean(np.diff(np.array(self.input_bounds), axis=1))\n",
        "            for pc in csts:\n",
        "                if pc[0].sense.value == 1: # <=\n",
        "                    if pc[0].right_expr.is_constant() and not pc[0].right_expr.is_zero():\n",
        "                        pc[0].right_expr -= np.random.uniform()*pc[0].right_expr\n",
        "                    else:\n",
        "                        pc[0].right_expr -= np.random.uniform()*avg_range\n",
        "                elif pc[0].sense.value == 3: # >=\n",
        "                    if pc[0].right_expr.is_constant() and not pc[0].right_expr.is_zero():\n",
        "                        pc[0].right_expr += np.random.uniform()*pc[0].right_expr\n",
        "                    else:\n",
        "                        pc[0].right_expr += np.random.uniform()*avg_range\n",
        "                print(\"\\n\", pc[0])\n",
        "                cplex.add_constraint(*pc)\n",
        "\n",
        "            ## quadratic random objective (boundaries)\n",
        "            obj = 0\n",
        "            for i, var in enumerate(xvars):\n",
        "                obj += (var-lhs_samples[p][i]) ** 2\n",
        "            cplex.set_objective(\"min\", obj)\n",
        "            \n",
        "            # solve\n",
        "            cplex.set_time_limit(30)\n",
        "            sol = cplex.solve()\n",
        "            if sol is None:\n",
        "                print(\"infeasible\")\n",
        "                continue\n",
        "            for i in range(self.input_shape):\n",
        "                x[p, i] = sol[\"x\"+str(i)]\n",
        "\n",
        "            p += 1\n",
        "            if p == n_points: break\n",
        "        print(\"Initial points:\\n\", x)\n",
        "\n",
        "        # eval fun\n",
        "        y = np.zeros((n_points))\n",
        "        for i in range(n_points):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "\n",
        "        return x,y\n",
        "\n",
        "    def get_grid(self, n_points):\n",
        "        x_list = []\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            lb = b[0]\n",
        "            ub = b[1]\n",
        "            if self.input_type[i] == \"int\":\n",
        "                x_list.append(np.arange(lb, ub, max(1, (ub-lb)//n_points)))\n",
        "            else:\n",
        "                x_list.append(np.arange(lb, ub, (ub-lb)/n_points))\n",
        "        x = np.array(np.meshgrid(*x_list)).reshape(self.input_shape,-1).T\n",
        "        y = np.zeros((x.shape[0]))\n",
        "        for i in range(x.shape[0]):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "95KSPh8oFams"
      },
      "outputs": [],
      "source": [
        "#@title Problem class - convex interpolation\n",
        "\n",
        "import docplex.mp.model as cpx\n",
        "import pandas as pd\n",
        "\n",
        "class Problem:\n",
        "\n",
        "    def __init__(self, name, fun, input_type, input_bounds, constraint_cb=None, stocasthic=False):\n",
        "        self.name = name\n",
        "        self.fun = fun\n",
        "        self.input_type = input_type\n",
        "        self.input_bounds = input_bounds\n",
        "        self.input_shape = len(self.input_bounds)\n",
        "        self.constraint_cb = constraint_cb\n",
        "        self.stocasthic = stocasthic\n",
        "\n",
        "    def get_dataset(self, n_points):\n",
        "        if self.constraint_cb is None:\n",
        "            x = np.random.rand(n_points, self.input_shape)\n",
        "            for i, b in enumerate(self.input_bounds):\n",
        "                lb = b[0]\n",
        "                ub = b[1]\n",
        "                if self.input_type[i] == \"int\":\n",
        "                    x[:,i] = np.random.randint(lb, high=ub, size=n_points)\n",
        "                else:\n",
        "                    x[:,i] *= ub - lb\n",
        "                    x[:,i] += lb\n",
        "            y = np.zeros((n_points))\n",
        "            for i in range(n_points):\n",
        "                y[i] = self.fun(x[i, :])\n",
        "            return x, y\n",
        "\n",
        "        # Constrained dataset:\n",
        "        x = np.zeros((n_points, self.input_shape))\n",
        "        bounds = []\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            if self.input_type[i] == \"int\":\n",
        "                bounds.append((int(b[0]), int(b[1])))\n",
        "            else:\n",
        "                bounds.append((float(b[0]), float(b[1])))\n",
        "\n",
        "        n_points_boundaries = n_points // 2\n",
        "        for p in range(n_points_boundaries):\n",
        "            cplex = cpx.Model()\n",
        "            xvars = []\n",
        "            for i,b in enumerate(self.input_bounds):\n",
        "                if self.input_type[i] == \"int\":\n",
        "                    xvars.append(cplex.integer_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "                else:\n",
        "                    xvars.append(cplex.continuous_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "            \n",
        "            csts = self.constraint_cb(cplex, xvars)\n",
        "            for pc in csts:\n",
        "                cplex.add_constraint(*pc)\n",
        "\n",
        "            # linear random objective (boundaries)\n",
        "            obj = 0\n",
        "            for var in xvars:\n",
        "                obj += var * (np.random.uniform()*2-1)\n",
        "            cplex.set_objective(\"max\", obj)\n",
        "            \n",
        "            # solve\n",
        "            cplex.set_time_limit(30)\n",
        "            sol = cplex.solve()\n",
        "            for i in range(self.input_shape):\n",
        "                x[p, i] = sol[\"x\"+str(i)]\n",
        "\n",
        "        # Interpolation  \n",
        "        for p in range(n_points_boundaries, n_points):\n",
        "            pidx = np.random.choice(n_points_boundaries, 2, replace=False)\n",
        "            p0, p1 = x[pidx[0]], x[pidx[1]]\n",
        "            step = np.random.uniform()\n",
        "            df = pd.DataFrame([p0, [np.nan]*self.input_shape, p1], \n",
        "                              index=[0, step, 1])\n",
        "            df = df.interpolate(method=\"index\")\n",
        "            x[p] = df.iloc[1].values\n",
        "\n",
        "        # eval fun\n",
        "        y = np.zeros((n_points))\n",
        "        for i in range(n_points):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "\n",
        "        return x,y\n",
        "\n",
        "    def get_grid(self, n_points):\n",
        "        x_list = []\n",
        "        for i, b in enumerate(self.input_bounds):\n",
        "            lb = b[0]\n",
        "            ub = b[1]\n",
        "            if self.input_type[i] == \"int\":\n",
        "                x_list.append(np.arange(lb, ub, max(1, (ub-lb)//n_points)))\n",
        "            else:\n",
        "                x_list.append(np.arange(lb, ub, (ub-lb)/n_points))\n",
        "        x = np.array(np.meshgrid(*x_list)).reshape(self.input_shape,-1).T\n",
        "        y = np.zeros((x.shape[0]))\n",
        "        for i in range(x.shape[0]):\n",
        "            y[i] = self.fun(x[i, :])\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97wo6u7pHxT"
      },
      "source": [
        "##TFP utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "Cj1QIgqNpSi3"
      },
      "outputs": [],
      "source": [
        "#@title Build and plot\n",
        "\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "def build_probabilistic_regressor(input_shape, depth=4, width=20):\n",
        "    mdl = tf.keras.Sequential()\n",
        "    mdl.add(tf.keras.layers.Input(shape=(input_shape,), dtype='float32'))\n",
        "    for i in range(depth):\n",
        "        mdl.add(tf.keras.layers.Dense(width, activation='relu'))\n",
        "    mdl.add(tf.keras.layers.Dense(2, activation='linear'))\n",
        "    lf = lambda t: tfp.distributions.Normal(loc=t[:, :1], \n",
        "                                            scale=tf.keras.backend.exp(t[:, 1:]))\n",
        "    mdl.add(tfp.layers.DistributionLambda(lf))\n",
        "    return mdl\n",
        "\n",
        "def dlambda_likelihood(y_true, dist):\n",
        "    return -dist.log_prob(y_true)\n",
        "\n",
        "def plot_prob_predictions(mdl, x, y):\n",
        "    prob_pred = mdl(np.expand_dims(x, axis=1))\n",
        "    pred = prob_pred.mean().numpy().ravel()\n",
        "    std_pred = prob_pred.stddev().numpy().ravel()\n",
        "    plt.plot(x, y, c=\"grey\")\n",
        "    plt.plot(x, pred)\n",
        "    plt.fill_between(x, pred-std_pred, pred+std_pred, \n",
        "                    alpha=0.3, color='tab:blue', label='+/- std')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWebt0aFQFWB"
      },
      "source": [
        "## EML utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "eKQuuVzEAFdY"
      },
      "outputs": [],
      "source": [
        "#@title Parse TFP model\n",
        "\n",
        "from eml.net.reader import keras_reader\n",
        "\n",
        "def parse_tfp(model):\n",
        "    in_shape = model.input_shape[1]\n",
        "    mdl_no_dist = tf.keras.Sequential()\n",
        "    mdl_no_dist.add(tf.keras.layers.Input(shape=(in_shape,), dtype='float32'))\n",
        "    for i in range(len(model.layers)-2):\n",
        "        w = model.layers[i].weights[1].shape[0]\n",
        "        mdl_no_dist.add(tf.keras.layers.Dense(w, activation='relu'))\n",
        "    mdl_no_dist.add(tf.keras.layers.Dense(2, activation='linear'))\n",
        "\n",
        "    mdl_no_dist.set_weights(model.get_weights())\n",
        "\n",
        "    nn = keras_reader.read_keras_sequential(mdl_no_dist)\n",
        "    return nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "d6sGBt_pBSDV"
      },
      "outputs": [],
      "source": [
        "#@title Bounds\n",
        "\n",
        "from eml.net.process import ibr_bounds, fwd_bound_tighthening\n",
        "\n",
        "def propagate_bound(bkd, parsed_model, bounds):\n",
        "    bounds = np.array(bounds)\n",
        "    parsed_model.layer(0).update_lb(bounds[:,0])\n",
        "    parsed_model.layer(0).update_ub(bounds[:,1])\n",
        "    fwd_bound_tighthening(bkd, parsed_model, timelimit=30)\n",
        "    print(\"Model output bounds:\\n\",parsed_model)\n",
        "    return parsed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "YaQm5IIOJKKh"
      },
      "outputs": [],
      "source": [
        "#@title Encode model\n",
        "\n",
        "from eml.backend import cplex_backend\n",
        "from eml.net import embed\n",
        "\n",
        "def embed_model(bkd, cplex, parsed_model, vtype, bounds):\n",
        "    mean_lb = parsed_model.layer(-1).lb()[0]  # bounds computed with propagate bounds method\n",
        "    mean_ub = parsed_model.layer(-1).ub()[0]\n",
        "    std_lb = parsed_model.layer(-1).lb()[1]\n",
        "    std_ub = parsed_model.layer(-1).ub()[1]\n",
        "\n",
        "    xvars = []\n",
        "    for i,b in enumerate(bounds):\n",
        "        xvars.append(cplex.continuous_var(lb=b[0], ub=b[1], name=\"x\"+str(i)))\n",
        "\n",
        "    yvars = [cplex.continuous_var(lb=mean_lb, ub=mean_ub, name=\"out_mean\"), \n",
        "            cplex.continuous_var(lb=std_lb, ub=std_ub, name=\"out_std\")]\n",
        "\n",
        "    embed.encode(bkd, parsed_model, cplex, xvars, yvars, 'nn')\n",
        "    return xvars, yvars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "Oacl6WbaqGkm"
      },
      "outputs": [],
      "source": [
        "#@title PWL helper\n",
        "\n",
        "from eml.util import encode_pwl\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "def pwl_exp(bkd, cplex, var, nnodes=7):\n",
        "    xx = np.linspace(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(math.exp, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=np.max(yy), name=\"exp_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_abs(bkd, cplex, var):\n",
        "    xx = np.array([-1, 0, 1])\n",
        "    yy = np.array([1, 0, 1])\n",
        "    v = [cplex.continuous_var(lb=0, ub=1), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_normal_cdf(bkd, cplex, var, nnodes=11):\n",
        "    xx = np.linspace(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(norm.cdf, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=1, name=\"ncdf_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_normal_pdf(bkd, cplex, var, nnodes=11):\n",
        "    xx = np.linspace(var.lb, var.ub, nnodes)\n",
        "    yy = np.array(list(map(norm.pdf, xx)))\n",
        "    v = [cplex.continuous_var(lb=0, ub=1, name=\"npdf_out\"), \n",
        "         var]\n",
        "    encode_pwl(bkd, cplex, v, [yy,xx])\n",
        "    return v[0]\n",
        "\n",
        "def pwl_sample_dist(bkd, cplex, vars, samples, vtype, bounds, nnodes=20):\n",
        "    mapf = lambda x: np.min(np.sum(np.abs(samples - x), axis=1)) / len(bounds)\n",
        "    p = Problem(None, mapf, vtype, bounds)\n",
        "    x,y = p.get_grid(nnodes)\n",
        "    ub = np.diff(np.array(bounds), axis=1)\n",
        "    ub = np.sum(ub)\n",
        "    v = [cplex.continuous_var(lb=0, ub=ub, name=\"dist_out\")]+vars\n",
        "    encode_pwl(bkd, cplex, v, [y,*x.T])\n",
        "    return v[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2oK4x9eI3W"
      },
      "source": [
        "## Optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "xC_4qcVo7u5Y"
      },
      "outputs": [],
      "source": [
        "#@title Base Experiment\n",
        "\n",
        "import time\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "class BaseExperiment:\n",
        "    def __init__(self, problem, starting_points, iterations, \n",
        "                 epochs, lr, weight_decay, depth, width, batch_size, \n",
        "                 solver_timeout):\n",
        "        set_seed()\n",
        "        self.problem = problem\n",
        "        self.starting_points = starting_points\n",
        "        self.iterations = iterations\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.depth = depth\n",
        "        self.width = width\n",
        "        self.batch_size = batch_size\n",
        "        self.solver_timeout = solver_timeout\n",
        "        self.x_samples, self.y_samples = problem.get_dataset(starting_points)\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def solver_optimization(self, keras_mdl):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def solution_log(self, solution):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_X(self, x):\n",
        "        bounds = np.array(self.problem.input_bounds)\n",
        "        return (x-bounds[:,0]) / (bounds[:,1]-bounds[:,0])\n",
        "\n",
        "    def normalize_Y(self, y):\n",
        "        min, max = np.min(self.y_samples), np.max(self.y_samples)\n",
        "        return (y-min) / (max-min)\n",
        "\n",
        "    def reverse_normalize_X(self, norm_x, milp_expr=False):\n",
        "        bounds = np.array(self.problem.input_bounds)\n",
        "        if milp_expr:  \n",
        "            # for cplex variables, np array not supported\n",
        "            bounds_range = np.squeeze(np.diff(bounds, axis=1))\n",
        "            xvars = []\n",
        "            for i,x in enumerate(norm_x):\n",
        "                xvars.append(x * bounds_range[i] + bounds[i,0])\n",
        "            return xvars\n",
        "        return (bounds[:,1]-bounds[:,0])*norm_x + bounds[:,0]\n",
        "\n",
        "    def reverse_normalize_Y(self, norm_y, stddev=False):\n",
        "        min, max = np.min(self.y_samples), np.max(self.y_samples)\n",
        "        if stddev:\n",
        "            return norm_y*(max-min)\n",
        "        return (max-min)*norm_y + min\n",
        "\n",
        "    def plot(self, hstory, keras_mdl):\n",
        "        if self.problem.input_shape <= 2:\n",
        "            x,y = self.problem.get_grid(100)\n",
        "            prob_pred = keras_mdl(self.normalize_X(x))\n",
        "            pred = prob_pred.mean().numpy().ravel()\n",
        "            pred = self.reverse_normalize_Y(pred)\n",
        "            std_pred = prob_pred.stddev().numpy().ravel()\n",
        "            std_pred = self.reverse_normalize_Y(std_pred, stddev=True)\n",
        "\n",
        "        plt.plot(hstory.history[\"loss\"])\n",
        "        plt.savefig('train_loss.png')\n",
        "        plt.show()\n",
        "        \n",
        "        fig = plt.figure(figsize=(15,10))\n",
        "        if self.problem.input_shape == 1:   # 1D domain\n",
        "            plt.xlim(self.problem.input_bounds[0])\n",
        "            x = np.squeeze(x)\n",
        "            plt.plot(x, y, c=\"grey\")\n",
        "            plt.plot(x, pred)\n",
        "            plt.fill_between(x, pred-std_pred, pred+std_pred, \n",
        "                            alpha=0.3, color='tab:blue', label='+/- std')\n",
        "            plt.scatter(self.x_samples, self.y_samples, c=\"orange\")\n",
        "            plt.legend([\"GT\", \"predicted mean\", \"predicted CI\", \"samples\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        elif self.problem.input_shape == 2:   # 2D domain\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "            ax.scatter(self.x_samples[:,0], self.x_samples[:,1], self.y_samples, color=\"orange\")\n",
        "            ax.scatter(x[:,0], x[:,1], y, alpha=0.15, color=\"lightgrey\")\n",
        "            ax.scatter(x[:,0], x[:,1], pred, alpha=0.3)\n",
        "            ax.scatter(x[:,0], x[:,1], pred-std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.scatter(x[:,0], x[:,1], pred+std_pred, alpha=0.3, color=\"lightblue\")\n",
        "            ax.view_init(elev=15, azim=60)\n",
        "            plt.legend([\"samples\", \"GT\", \"predicted mean\", \"predicted CI\"])\n",
        "            plt.savefig('chart.png')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Plot not available for high dimensional domains.\")\n",
        "            print(f\"X:\\n{self.x_samples}\\nY:\\n{self.y_samples}\")\n",
        "            prob_pred = keras_mdl(self.normalize_X(self.x_samples))\n",
        "            mu = self.reverse_normalize_Y(prob_pred.mean().numpy().ravel())\n",
        "            print(\"mu pred\\n\",mu)\n",
        "            print(\"diff\\n\",self.y_samples-mu)\n",
        "\n",
        "    def run(self):\n",
        "        not_improve = 0\n",
        "        for iteration in range(self.iterations):\n",
        "            # build NN\n",
        "            print(f\"Iteration {iteration}:\", \"=\"*20)\n",
        "            optimizer = tfa.optimizers.AdamW(weight_decay=self.weight_decay,\n",
        "                                             learning_rate=self.lr)\n",
        "            keras_mdl = build_probabilistic_regressor(\n",
        "                self.problem.input_shape, self.depth, self.width)\n",
        "            keras_mdl.compile(optimizer=optimizer, loss=dlambda_likelihood)\n",
        "            keras_mdl.summary()\n",
        "\n",
        "            # train\n",
        "            train_time = time.time()\n",
        "            keras_mdl, hstory = self.train(keras_mdl)\n",
        "            train_time = time.time() - train_time\n",
        "\n",
        "            # plot loss and predictions if domain dim <= 2\n",
        "            self.plot(hstory, keras_mdl)\n",
        "\n",
        "            # MILP solver\n",
        "            solver_time = time.time()\n",
        "            sol = self.solver_optimization(iteration, not_improve, keras_mdl)\n",
        "            solver_time = time.time() - solver_time\n",
        "\n",
        "            if sol is None:\n",
        "                print(f'Not feasible')\n",
        "                break\n",
        "            sol.solve_details.print_information()\n",
        "\n",
        "            # retrieve solution\n",
        "            opt_x = np.zeros(self.problem.input_shape)\n",
        "            for i in range(self.problem.input_shape):\n",
        "                opt_x[i] = sol[\"x\"+str(i)]\n",
        "            opt_x = self.reverse_normalize_X(opt_x)\n",
        "            \n",
        "            # retrieve integer solutions\n",
        "            for i in range(self.problem.input_shape):\n",
        "                if self.problem.input_type[i] == \"int\":\n",
        "                    opt_x[i] = sol[\"int_x\"+str(i)]\n",
        "\n",
        "            # check if repeated data point and query obj function\n",
        "            dists = np.sum(np.abs(self.x_samples - np.expand_dims(opt_x, 0)), axis=1)\n",
        "            dmin = np.min(dists)\n",
        "            dargmin = np.argmin(dists)\n",
        "            # For non stocasthic problems, avoid resampling the same points, but giving much sample weight\n",
        "            if not self.problem.stocasthic and dmin <= 1e-6: \n",
        "                print(\"Preventing query for an already known point !\")\n",
        "                opt_y = self.y_samples[dargmin]\n",
        "            else:\n",
        "                # BBF query\n",
        "                opt_y = self.problem.fun(opt_x)\n",
        "\n",
        "            # log new point\n",
        "            emean = self.reverse_normalize_Y(sol['out_mean'])\n",
        "            print(f\"opt input={opt_x}, expected mean={emean}, gt={opt_y}\")\n",
        "            print(f\"train time: {train_time}, solver time: {solver_time}\")\n",
        "\n",
        "            # not improve counter\n",
        "            if opt_y < np.min(self.y_samples):\n",
        "                not_improve = 0\n",
        "            else:\n",
        "                not_improve += 1\n",
        "            \n",
        "            # add new point to the dataset\n",
        "            self.x_samples = np.concatenate((self.x_samples, np.expand_dims(opt_x, 0)))\n",
        "            self.y_samples = np.append(self.y_samples, opt_y)\n",
        "\n",
        "            # log and WandB\n",
        "            if iteration == 0 and ENABLE_WANDB: # log starting points before the first iteration\n",
        "                for j in range(self.starting_points):\n",
        "                    wandb.log({\"x_sample\": self.x_samples[j], \"y_sample\": self.y_samples[j]})\n",
        "                \n",
        "            self.solution_log(sol)\n",
        "\n",
        "            if ENABLE_WANDB: \n",
        "                if self.problem.input_shape <= 2:\n",
        "                    wandb.log({\"train_predictions\": wandb.Image('chart.png')}, commit=False)\n",
        "                wandb.log({\n",
        "                    \"train_loss\": wandb.Image('train_loss.png'),\n",
        "                    \"x_sample\": opt_x, \"y_sample\": opt_y, \"y_min\": np.min(self.y_samples),\n",
        "                    \"train_time\": train_time, \"solver_time\": solver_time\n",
        "                })\n",
        "        # == end opt loop\n",
        "        print(f\"Min found: {np.min(self.y_samples)} in {np.argmin(self.y_samples)+1-self.starting_points} iterations\")\n",
        "        if ENABLE_WANDB:\n",
        "            wandb.log({\n",
        "                \"min_found\": np.min(self.y_samples),\n",
        "                \"n_iterations\": np.argmin(self.y_samples)+1-self.starting_points\n",
        "            })\n",
        "\n",
        "        # Dump points for future studies\n",
        "        dump_points = list(zip(self.x_samples, self.y_samples))\n",
        "        with open('points.pkl', 'wb') as f:\n",
        "            pickle.dump(dump_points, f)\n",
        "        if ENABLE_WANDB:\n",
        "            artifact = wandb.Artifact('datapoints', type='points')\n",
        "            artifact.add_file(\"points.pkl\")\n",
        "            wandb.log_artifact(artifact)\n",
        "\n",
        "        ymin = np.min(self.y_samples)\n",
        "        yargmin = np.argmin(self.y_samples)\n",
        "        xmin = self.x_samples[yargmin]\n",
        "        return ymin, xmin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "sEFhpl6xi54I"
      },
      "outputs": [],
      "source": [
        "#@title Base UCB\n",
        "\n",
        "class BaseUCBExperiment(BaseExperiment):\n",
        "\n",
        "    def __init__(self, beta_ucb, *args, **kwargs):\n",
        "        super(BaseUCBExperiment, self).__init__(*args, **kwargs)\n",
        "        self.beta = beta_ucb\n",
        "\n",
        "    def solver_optimization(self, iteration, not_improve, keras_mdl):\n",
        "        print(\"UCB solver...\")\n",
        "        cplex = cpx.Model()\n",
        "        bkd = cplex_backend.CplexBackend()\n",
        "\n",
        "        parsed_mdl = parse_tfp(keras_mdl)\n",
        "        propagate_bound(parsed_mdl, [[0,1]]*self.problem.input_shape)\n",
        "        xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                   self.problem.input_type,\n",
        "                                   [[0,1]]*self.problem.input_shape)\n",
        "\n",
        "        stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "        # Problem contraints\n",
        "        if self.problem.constraint_cb is not None:\n",
        "            rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "            self.problem.constraint_cb(cplex, rev_norm_xvars)\n",
        "        \n",
        "        ucb = -yvars[0] + self.beta * stddev\n",
        "        cplex.set_objective('max', ucb)\n",
        "        cplex.set_time_limit(self.solver_timeout)\n",
        "        sol = cplex.solve()\n",
        "\n",
        "        print(cplex.solve_details)\n",
        "        cplex.print_information()\n",
        "        return sol\n",
        "\n",
        "    def solution_log(self, solution):\n",
        "        print(f\"UCB: {solution.objective_value}\")\n",
        "        if ENABLE_WANDB: \n",
        "            wandb.log({\n",
        "                \"ucb\": solution['ucb'],\n",
        "                \"exp_err\": solution['exp_out'] - math.exp(solution['out_std'])\n",
        "            }, commit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "UqLsO46NeTmX"
      },
      "outputs": [],
      "source": [
        "#@title Stop CI\n",
        "\n",
        "class StopCICB(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, threshold, *args, **kwargs):\n",
        "        super(StopCICB, self).__init__(*args, **kwargs)\n",
        "        self.threshold = threshold\n",
        "        self.x = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        prob_pred = self.model(self.x)\n",
        "        std_pred = prob_pred.stddev().numpy().ravel()\n",
        "        if epoch % 100 == 0:\n",
        "            print(epoch, \"mean stddev\", np.mean(std_pred))\n",
        "        if np.mean(std_pred) < self.threshold:\n",
        "            print(\"break condition on epoch\", epoch, \"with mean stddev\", np.mean(std_pred))\n",
        "            self.model.stop_training = True\n",
        "\n",
        "class StopCI(BaseUCBExperiment):\n",
        "\n",
        "    def __init__(self, ci_threshold, *args, **kwargs):\n",
        "        super(StopCI, self).__init__(*args, **kwargs)\n",
        "        self.ci_threshold = ci_threshold\n",
        "        stop_ci = StopCICB(self.ci_threshold)\n",
        "        self.cb = [stop_ci]\n",
        "\n",
        "    def train(self, keras_mdl):\n",
        "        print(\"Stop CI training...\")\n",
        "        bs = self.batch_size if self.batch_size else self.x_samples.shape[0]\n",
        "\n",
        "        norm_x = self.normalize_X(self.x_samples)\n",
        "        norm_y = self.normalize_Y(self.y_samples)\n",
        "\n",
        "        self.cb[0].x = norm_x\n",
        "\n",
        "        hstory = keras_mdl.fit(norm_x, norm_y,\n",
        "                batch_size=bs, epochs=self.epochs, verbose=0, callbacks=self.cb)\n",
        "\n",
        "        return keras_mdl, hstory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "iIUvAeW-hUwG"
      },
      "outputs": [],
      "source": [
        "#@title Beta decay\n",
        "\n",
        "class BetaDecay(StopCI):\n",
        "\n",
        "    def __init__(self, lns_fixed, *args, **kwargs):\n",
        "        super(BetaDecay, self).__init__(*args, **kwargs)\n",
        "        self.lns_fixed = lns_fixed\n",
        "\n",
        "    def solver_optimization(self, iteration, not_improve, keras_mdl):\n",
        "        print(\"Distance based UCB solver...\")\n",
        "\n",
        "        ## K-Lipschitz with L1 dist\n",
        "        k_lip = 0\n",
        "        qlist = []\n",
        "        for i in range(self.x_samples.shape[0]):\n",
        "            for j in range(i+1, self.x_samples.shape[0]):\n",
        "                delta_y = np.abs(self.y_samples[i]-self.y_samples[j])\n",
        "                delta_x = np.sum(np.abs(self.x_samples[i]-self.x_samples[j]))/self.problem.input_shape\n",
        "                if delta_x >= 1e-6: #eps to avoid inf\n",
        "                    k_lip = max(k_lip, delta_y/delta_x)\n",
        "                    qlist.append(delta_y/delta_x)\n",
        "        print(\"K-Lipschitz max:\", k_lip, \n",
        "              \"95 percentile:\", np.percentile(qlist, 95, interpolation='linear'))\n",
        "        \n",
        "        solution = None\n",
        "        feature_fixed = self.problem.input_shape - (self.problem.input_shape // self.lns_fixed)\n",
        "        for lns_i in range(self.lns_fixed):\n",
        "            print(\"@\"*20, \"LSN iteration:\", lns_i)\n",
        "            cplex = cpx.Model()\n",
        "            bkd = cplex_backend.CplexBackend()\n",
        "            norm_x = self.normalize_X(self.x_samples)\n",
        "\n",
        "            ## Beta\n",
        "            if self.beta is not None:\n",
        "                self.current_beta = self.beta\n",
        "            else:\n",
        "                self.current_beta = k_lip * ((1-iteration/ITERATIONS)**4)\n",
        "\n",
        "            ## LNS\n",
        "            best = norm_x[np.argmin(self.y_samples)]\n",
        "            selection = np.random.choice(self.problem.input_shape, feature_fixed, replace=False)\n",
        "            print(\"LNS Random selection\", selection, \"best:\", best)\n",
        "            pbounds = [[0,1]]*self.problem.input_shape\n",
        "            for v in selection:\n",
        "                pbounds[v] = [best[v], best[v]]\n",
        "            \n",
        "            ## NN encoding\n",
        "            parsed_mdl = parse_tfp(keras_mdl)\n",
        "            print(\"Propagating bounds...\")\n",
        "            propagate_bound(bkd, parsed_mdl, pbounds)\n",
        "            xvars, yvars = embed_model(bkd, cplex, parsed_mdl, \n",
        "                                    self.problem.input_type,\n",
        "                                    pbounds)\n",
        "\n",
        "            # Handle integer variables\n",
        "            for idx, bound in enumerate(self.problem.input_bounds):\n",
        "                if self.problem.input_type[idx] == \"int\":\n",
        "                    int_cst = cplex.integer_var(lb=bound[0], ub=bound[1], name=\"int_x\"+str(idx))\n",
        "                    cplex.add_constraint(int_cst == xvars[idx]*(bound[1]-bound[0])+bound[0])\n",
        "            \n",
        "            ## EXP PWL\n",
        "            stddev = pwl_exp(bkd, cplex, yvars[1], nnodes=7)\n",
        "\n",
        "            #################### Distance section\n",
        "            # Sample distance\n",
        "            sample_distance_list = []\n",
        "            for row in range(norm_x.shape[0]):\n",
        "                current_sample_dist = 0\n",
        "                for feature in range(norm_x.shape[1]):\n",
        "                    current_sample_dist += cplex.abs(norm_x[row, feature] - xvars[feature])\n",
        "                sample_distance_list.append(current_sample_dist)\n",
        "            \n",
        "            ## triangular inequality\n",
        "            def l1_dist(a,b): \n",
        "                return np.sum(np.abs(a-b))\n",
        "            for id_xy in range(len(sample_distance_list)):\n",
        "                s_xy = sample_distance_list[id_xy]\n",
        "                for id_xz in range(id_xy, len(sample_distance_list)):\n",
        "                    s_xz = sample_distance_list[id_xz]\n",
        "                    cplex.add_constraint(s_xy <= s_xz + l1_dist(norm_x[id_xy],norm_x[id_xz]), \"traingular inequality\")\n",
        "\n",
        "            # Min distance\n",
        "            min_dist = cplex.continuous_var(lb=0, ub=self.problem.input_shape, name=\"dist\")\n",
        "            for current_sample_dist in sample_distance_list:\n",
        "                cplex.add_constraint(current_sample_dist >= min_dist, \"min dist\")  # scale down the l1 dist with dimensions\n",
        "            #################### END Distance section\n",
        "            \n",
        "            # Problem contraints\n",
        "            if self.problem.constraint_cb is not None:\n",
        "                rev_norm_xvars = self.reverse_normalize_X(xvars, True)\n",
        "                csts = self.problem.constraint_cb(cplex, rev_norm_xvars)\n",
        "                for pc in csts:\n",
        "                    cplex.add_constraint(*pc)\n",
        "\n",
        "            # UCB\n",
        "            ucb = -yvars[0] + \\\n",
        "                self.current_beta * stddev + \\\n",
        "                (self.current_beta/self.problem.input_shape) * min_dist\n",
        "\n",
        "            cplex.set_objective('max', ucb)\n",
        "            cplex.set_time_limit(self.solver_timeout)\n",
        "\n",
        "            cplex.parameters.mip.strategy.nodeselect = 2\n",
        "\n",
        "            # CPLEX log\n",
        "            cplex.context.solver.verbose = 5\n",
        "            cplex.context.solver.log_output = True\n",
        "\n",
        "            cplex.print_information()\n",
        "            box = sys.stdout\n",
        "            sys.stdout = open('cplex_model.txt', 'w')\n",
        "            cplex.prettyprint()\n",
        "            sys.stdout.close()\n",
        "            sys.stdout = box\n",
        "\n",
        "            print(\"Solving...\")\n",
        "            sol = cplex.solve()\n",
        "\n",
        "            if sol is not None:\n",
        "                if solution is not None:\n",
        "                    if sol.objective_value > solution.objective_value:\n",
        "                        solution = sol\n",
        "                else:\n",
        "                    solution = sol\n",
        "\n",
        "        return solution\n",
        "\n",
        "    def solution_log(self, solution):\n",
        "        print(\"Beta:\", self.current_beta)\n",
        "        print(\"Normalized Dist:\", solution['dist'])\n",
        "        print(f\"UCB: {solution.objective_value}\")\n",
        "        print(\"mean:\", solution['out_mean'])\n",
        "        print(\"logstd:\", solution['out_std'])\n",
        "        print(\"truestd:\", math.exp(solution['out_std']))\n",
        "        print(\"stddev:\", solution['exp_out'])\n",
        "        if ENABLE_WANDB: \n",
        "            wandb.log({\n",
        "                \"ucb\": solution.objective_value,\n",
        "                \"norm_dist\": solution['dist'],\n",
        "                \"mean\": solution['out_mean'],\n",
        "                \"stddev\": solution['exp_out'],\n",
        "                \"exp_err\": solution['exp_out'] - math.exp(solution['out_std']),\n",
        "                \"beta_ucb\": self.current_beta\n",
        "            }, commit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW0oUNuGetvq"
      },
      "source": [
        "# 🚀 Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U3k-S4lGbtIu"
      },
      "outputs": [],
      "source": [
        "#@title 📈 Parameters and WandB\n",
        "\n",
        "ITERATIONS =                                  50#@param {type:\"integer\"}\n",
        "STARTING_POINTS =                              5#@param {type:\"integer\"}\n",
        "\n",
        "EPOCHS =                                    999#@param {type:\"integer\"}  \n",
        "\n",
        "LR =                                        1e-3#@param {type:\"number\"}\n",
        "WEIGHT_DECAY =                                        1e-4#@param {type:\"number\"}\n",
        "BATCH_SIZE = None                               #@param {type:\"raw\"} None = all samples in 1 batch\n",
        "DEPTH =                                        1#@param {type:\"integer\"}\n",
        "WIDTH =                                       200#@param {type:\"integer\"}\n",
        "\n",
        "BETA_UCB =                                     1#@param {type:\"raw\"}\n",
        "\n",
        "SOLVER_TIMEOUT =                              120#@param {type:\"integer\"}\n",
        "\n",
        "CI_THRESHOLD =              0.05#@param {type:\"raw\"} \n",
        "LNS_FIXED =              1#@param {type:\"integer\"} \n",
        "#@markdown ---\n",
        "# set if you plan to log on wandb\n",
        "ENABLE_WANDB = True                            #@param {type:\"boolean\"}        \n",
        "EXPERIMENT_NAME = \"example_experiment\"          #@param {type:\"string\"}\n",
        "\n",
        "if ENABLE_WANDB and \"wandb\" not in sys.modules:\n",
        "    !pip install wandb > /dev/null\n",
        "    !wandb login\n",
        "    import wandb\n",
        "\n",
        "def init_wandb(experiment_name, run_id):\n",
        "    if run_id is not None: \n",
        "        wandb.init(project='eml', id=run_id, resume='allow')\n",
        "    else:\n",
        "        wandb.init(project='eml', name=experiment_name)\n",
        "\n",
        "        wandb.config.iterations = ITERATIONS\n",
        "        wandb.config.starting_points = STARTING_POINTS\n",
        "        wandb.config.epochs = EPOCHS\n",
        "        wandb.config.lr = LR\n",
        "        wandb.config.weight_decay = WEIGHT_DECAY\n",
        "        wandb.config.batch_size = BATCH_SIZE\n",
        "        wandb.config.depth = DEPTH\n",
        "        wandb.config.width = WIDTH\n",
        "        wandb.config.beta_ucb = BETA_UCB\n",
        "        wandb.config.solver_timeout = SOLVER_TIMEOUT\n",
        "        wandb.config.ci_threshold = CI_THRESHOLD\n",
        "        wandb.config.lns_fixed = LNS_FIXED\n",
        "\n",
        "def run_experiment(target):\n",
        "    instance = BetaDecay(\n",
        "        LNS_FIXED,\n",
        "        CI_THRESHOLD, \n",
        "        BETA_UCB, \n",
        "        target, STARTING_POINTS, ITERATIONS, \n",
        "        EPOCHS, LR, WEIGHT_DECAY, DEPTH, WIDTH, BATCH_SIZE, \n",
        "        SOLVER_TIMEOUT)\n",
        "    return instance.run()\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    init_wandb(EXPERIMENT_NAME, None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCI6spRykVDi"
      },
      "outputs": [],
      "source": [
        "#@title ▶️ Run experiment\n",
        "\n",
        "# objective function\n",
        "def obj_ackley(x):\n",
        "    x1,x2 = x[0],x[1]\n",
        "    return -20*math.exp(-0.2*math.sqrt(0.5*(x1*x1+x2*x2))) - \\\n",
        "        math.exp(0.5*(math.cos(2*math.pi*x1)+math.cos(2*math.pi*x2))) + \\\n",
        "        math.e + 20\n",
        "\n",
        "# constraint\n",
        "def cst_disk(cplex, xvars):     # x1^2 + x2^2 < r^2\n",
        "    x1,x2 = xvars\n",
        "    r = 2\n",
        "    return [[x1*x1 + x2*x2 <= r*r, \"center_dist\"]]\n",
        "\n",
        "# define problem\n",
        "example_problem = Problem(\n",
        "        \"example_problem\", \n",
        "        obj_ackley, \n",
        "        [\"real\", \"real\"],\n",
        "        [[-3, 3], [-2, 2]],\n",
        "        cst_disk, \n",
        "        stocasthic=False)\n",
        "\n",
        "#---------------- Start optimization ----------------#\n",
        "run_experiment(example_problem)\n",
        "#----------------------------------------------------#"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nNNmQ5x5YJaS",
        "JcyNrxy43Bgb"
      ],
      "name": "release.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}